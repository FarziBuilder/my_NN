{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d59e653",
   "metadata": {
    "papermill": {
     "duration": 0.12876,
     "end_time": "2022-11-16T07:29:54.463832",
     "exception": false,
     "start_time": "2022-11-16T07:29:54.335072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5921d76",
   "metadata": {
    "papermill": {
     "duration": 0.124608,
     "end_time": "2022-11-16T07:29:54.713489",
     "exception": false,
     "start_time": "2022-11-16T07:29:54.588881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook we're going to build and train a deep learning model \"from scratch\" -- by which I mean that we're not going to use any pre-built architecture, or optimizers, or data loading frameworks, etc.\n",
    "\n",
    "We'll be assuming you already know the basics of how a neural network works. If you don't, read this notebook first: [How does a neural net really work?\n",
    "](https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work). We'll be using Kaggle's [Titanic](https://www.kaggle.com/competitions/titanic/) competition in this notebook, because it's very small and simple, but also has displays many of the tricky real-life issues that we need to handle in most practical projects. (Note, however, that this competition is a small \"learner\" competition on Kaggle, so don't expect to actually see much benefits from using a neural net just yet; that will come once we try our some real competitions!)\n",
    "\n",
    "It's great to be able to run the same notebook on your own machine or Colab, as well as Kaggle. To allow for this, we use this code to download the data as needed when not on Kaggle (see [this notebook](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/) for details about this technique):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7c4085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:29:54.966892Z",
     "iopub.status.busy": "2022-11-16T07:29:54.966583Z",
     "iopub.status.idle": "2022-11-16T07:29:54.977128Z",
     "shell.execute_reply": "2022-11-16T07:29:54.975952Z"
    },
    "papermill": {
     "duration": 0.140291,
     "end_time": "2022-11-16T07:29:54.979666",
     "exception": false,
     "start_time": "2022-11-16T07:29:54.839375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if iskaggle: path = Path('../input/titanic')\n",
    "else:\n",
    "    path = Path('titanic')\n",
    "    if not path.exists():\n",
    "        import zipfile,kaggle\n",
    "        kaggle.api.competition_download_cli(str(path))\n",
    "        zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc8c22",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.123478,
     "end_time": "2022-11-16T07:29:55.227711",
     "exception": false,
     "start_time": "2022-11-16T07:29:55.104233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that the data for Kaggle comps always lives in the `../input` folder. The easiest way to get the path is to click the \"K\" button in the top-right of the Kaggle notebook, click on the folder shown there, and click the copy button.\n",
    "\n",
    "We'll be using *numpy* and *pytorch* for array calculations in this notebook, and *pandas* for working with tabular data, so we'll import them and set them to display using a bit more space than they default to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a2f3a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:29:55.493483Z",
     "iopub.status.busy": "2022-11-16T07:29:55.493245Z",
     "iopub.status.idle": "2022-11-16T07:29:56.753239Z",
     "shell.execute_reply": "2022-11-16T07:29:56.752387Z"
    },
    "papermill": {
     "duration": 1.388786,
     "end_time": "2022-11-16T07:29:56.755680",
     "exception": false,
     "start_time": "2022-11-16T07:29:55.366894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979450a3",
   "metadata": {
    "heading_collapsed": true,
    "papermill": {
     "duration": 0.125959,
     "end_time": "2022-11-16T07:29:57.006863",
     "exception": false,
     "start_time": "2022-11-16T07:29:56.880904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea01e468",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.123564,
     "end_time": "2022-11-16T07:29:57.253244",
     "exception": false,
     "start_time": "2022-11-16T07:29:57.129680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is a *tabular data* competition -- the data is in the form of a table. It's provided as a Comma Separated Values (CSV) file. We can open it using the *pandas* library, which will create a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64e4207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:29:57.507629Z",
     "iopub.status.busy": "2022-11-16T07:29:57.507356Z",
     "iopub.status.idle": "2022-11-16T07:29:57.555118Z",
     "shell.execute_reply": "2022-11-16T07:29:57.554282Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.176606,
     "end_time": "2022-11-16T07:29:57.556902",
     "exception": false,
     "start_time": "2022-11-16T07:29:57.380296",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d54b84",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.124239,
     "end_time": "2022-11-16T07:29:57.806130",
     "exception": false,
     "start_time": "2022-11-16T07:29:57.681891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we learned in the *How does a neural net really work* notebook, we going to want to multiply each column by some coefficients. But we can see in the `Cabin` column that there are `NaN` values, which is how Pandas refers to missing values. We can't multiply something by a missing value!\n",
    "\n",
    "Let's check which columns contain `NaN` values. Pandas' `isna()` function returns `True` (which is treated as `1` when used as a number) for `NaN` values, so we can just add them up for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d8f875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:29:58.056784Z",
     "iopub.status.busy": "2022-11-16T07:29:58.055919Z",
     "iopub.status.idle": "2022-11-16T07:29:58.076053Z",
     "shell.execute_reply": "2022-11-16T07:29:58.075504Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.147028,
     "end_time": "2022-11-16T07:29:58.077760",
     "exception": false,
     "start_time": "2022-11-16T07:29:57.930732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Name    Sex    Age  SibSp  Parch  Ticket   Fare  Cabin  Embarked\n",
       "0          False     False   False  False  False  False  False  False   False  False   True     False\n",
       "1          False     False   False  False  False  False  False  False   False  False  False     False\n",
       "2          False     False   False  False  False  False  False  False   False  False   True     False\n",
       "3          False     False   False  False  False  False  False  False   False  False  False     False\n",
       "4          False     False   False  False  False  False  False  False   False  False   True     False\n",
       "..           ...       ...     ...    ...    ...    ...    ...    ...     ...    ...    ...       ...\n",
       "886        False     False   False  False  False  False  False  False   False  False   True     False\n",
       "887        False     False   False  False  False  False  False  False   False  False  False     False\n",
       "888        False     False   False  False  False   True  False  False   False  False   True     False\n",
       "889        False     False   False  False  False  False  False  False   False  False  False     False\n",
       "890        False     False   False  False  False  False  False  False   False  False   True     False\n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e75c156",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.127537,
     "end_time": "2022-11-16T07:29:58.330378",
     "exception": false,
     "start_time": "2022-11-16T07:29:58.202841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice that by default Pandas sums over columns.\n",
    "\n",
    "We'll need to replace the missing values with something. It doesn't generally matter too much what we choose. We'll use the most common value (the \"*mode*\"). We can use the `mode` function for that. One wrinkle is that it returns more than one row in the case of ties, so we just grab the first row with `iloc[0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99f7399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:29:58.583487Z",
     "iopub.status.busy": "2022-11-16T07:29:58.583035Z",
     "iopub.status.idle": "2022-11-16T07:29:58.602530Z",
     "shell.execute_reply": "2022-11-16T07:29:58.601965Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.147862,
     "end_time": "2022-11-16T07:29:58.604283",
     "exception": false,
     "start_time": "2022-11-16T07:29:58.456421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "modes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6637c869",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.125319,
     "end_time": "2022-11-16T07:29:58.856423",
     "exception": false,
     "start_time": "2022-11-16T07:29:58.731104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "BTW, it's never a good idea to use functions without understanding them. So be sure to google for anything you're not familiar with. E.g if you want to learn about `iloc` (which is a very important function indeed!) then Google will give you a link to a [great tutorial](https://www.shanelynn.ie/pandas-iloc-loc-select-rows-and-columns-dataframe/).\n",
    "\n",
    "Now that we've got the mode of each column, we can use `fillna` to replace the missing values with the mode of each column. We'll do it \"in place\" -- meaning that we'll change the dataframe itself, rather than returning a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d04e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:29:59.115456Z",
     "iopub.status.busy": "2022-11-16T07:29:59.115011Z",
     "iopub.status.idle": "2022-11-16T07:29:59.124458Z",
     "shell.execute_reply": "2022-11-16T07:29:59.123951Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.139416,
     "end_time": "2022-11-16T07:29:59.126488",
     "exception": false,
     "start_time": "2022-11-16T07:29:58.987072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e081bf3",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.124525,
     "end_time": "2022-11-16T07:29:59.375761",
     "exception": false,
     "start_time": "2022-11-16T07:29:59.251236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now check there's no missing values left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1735407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:29:59.630808Z",
     "iopub.status.busy": "2022-11-16T07:29:59.630332Z",
     "iopub.status.idle": "2022-11-16T07:29:59.637119Z",
     "shell.execute_reply": "2022-11-16T07:29:59.636668Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.136277,
     "end_time": "2022-11-16T07:29:59.638978",
     "exception": false,
     "start_time": "2022-11-16T07:29:59.502701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96415928",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.128807,
     "end_time": "2022-11-16T07:29:59.895145",
     "exception": false,
     "start_time": "2022-11-16T07:29:59.766338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here's how we get a quick summary of all the numeric columns in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aebed797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:00.154871Z",
     "iopub.status.busy": "2022-11-16T07:30:00.154417Z",
     "iopub.status.idle": "2022-11-16T07:30:00.184915Z",
     "shell.execute_reply": "2022-11-16T07:30:00.183818Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.163256,
     "end_time": "2022-11-16T07:30:00.187222",
     "exception": false,
     "start_time": "2022-11-16T07:30:00.023966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=(np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c159d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T11:02:34.328433Z",
     "iopub.status.busy": "2022-05-13T11:02:34.327999Z",
     "iopub.status.idle": "2022-05-13T11:02:34.336993Z",
     "shell.execute_reply": "2022-05-13T11:02:34.335466Z",
     "shell.execute_reply.started": "2022-05-13T11:02:34.32838Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.126932,
     "end_time": "2022-11-16T07:30:00.443957",
     "exception": false,
     "start_time": "2022-11-16T07:30:00.317025",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that `Fare` contains mainly values of around `0` to `30`, but there's a few really big ones. This is very common with fields contain monetary values, and it can cause problems for our model, because once that column is multiplied by a coefficient later, the few rows with really big values will dominate the result.\n",
    "\n",
    "You can see the issue most clearly visually by looking at a histogram, which shows a long tail to the right (and don't forget: if you're not entirely sure what a histogram is, Google \"[histogram tutorial](https://www.google.com/search?q=histogram+tutorial&oq=histogram+tutorial)\" and do a bit of reading before continuing on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6085040a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:00.708587Z",
     "iopub.status.busy": "2022-11-16T07:30:00.708287Z",
     "iopub.status.idle": "2022-11-16T07:30:00.930016Z",
     "shell.execute_reply": "2022-11-16T07:30:00.929400Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.358159,
     "end_time": "2022-11-16T07:30:00.931653",
     "exception": false,
     "start_time": "2022-11-16T07:30:00.573494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Age'].mode\n",
    "\n",
    "df['Fare'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695f8b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T11:02:34.328433Z",
     "iopub.status.busy": "2022-05-13T11:02:34.327999Z",
     "iopub.status.idle": "2022-05-13T11:02:34.336993Z",
     "shell.execute_reply": "2022-05-13T11:02:34.335466Z",
     "shell.execute_reply.started": "2022-05-13T11:02:34.32838Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.128531,
     "end_time": "2022-11-16T07:30:01.190683",
     "exception": false,
     "start_time": "2022-11-16T07:30:01.062152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To fix this, the most common approach is to take the logarithm, which squishes the big numbers and makes the distribution more reasonable. Note, however, that there are zeros in the `Fare` column, and `log(0)` is infinite -- to fix this, we'll simply add `1` to all values first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fcdacc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:01.450475Z",
     "iopub.status.busy": "2022-11-16T07:30:01.450166Z",
     "iopub.status.idle": "2022-11-16T07:30:01.454872Z",
     "shell.execute_reply": "2022-11-16T07:30:01.454238Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.137303,
     "end_time": "2022-11-16T07:30:01.457258",
     "exception": false,
     "start_time": "2022-11-16T07:30:01.319955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['LogFare']=np.log(df[\n",
    "    'Fare']+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495efe91",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.128285,
     "end_time": "2022-11-16T07:30:01.715003",
     "exception": false,
     "start_time": "2022-11-16T07:30:01.586718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The histogram now shows a more even distribution of values without the long tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a9833f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:01.972672Z",
     "iopub.status.busy": "2022-11-16T07:30:01.972214Z",
     "iopub.status.idle": "2022-11-16T07:30:02.140686Z",
     "shell.execute_reply": "2022-11-16T07:30:02.139496Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.301342,
     "end_time": "2022-11-16T07:30:02.143190",
     "exception": false,
     "start_time": "2022-11-16T07:30:01.841848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LogFare'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bbec9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:02.401495Z",
     "iopub.status.busy": "2022-11-16T07:30:02.401155Z",
     "iopub.status.idle": "2022-11-16T07:30:02.427773Z",
     "shell.execute_reply": "2022-11-16T07:30:02.426754Z"
    },
    "papermill": {
     "duration": 0.158301,
     "end_time": "2022-11-16T07:30:02.430029",
     "exception": false,
     "start_time": "2022-11-16T07:30:02.271728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>LogFare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>2.962246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.969048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>2.187218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>2.737881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.465736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>6.240917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare     LogFare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208    2.962246\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429    0.969048\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400    2.187218\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200    2.737881\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000    3.465736\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200    6.240917"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=(np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcffc126",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.12792,
     "end_time": "2022-11-16T07:30:02.689040",
     "exception": false,
     "start_time": "2022-11-16T07:30:02.561120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It looks from the `describe()` output like `Pclass` contains just 3 values, which we can confirm by looking at the [Data Dictionary](https://www.kaggle.com/competitions/titanic/data) (which you should always study carefully for any project!) -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b434c6",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.128495,
     "end_time": "2022-11-16T07:30:02.948070",
     "exception": false,
     "start_time": "2022-11-16T07:30:02.819575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdfd6ff",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.127658,
     "end_time": "2022-11-16T07:30:03.202560",
     "exception": false,
     "start_time": "2022-11-16T07:30:03.074902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here's how we get a quick summary of all the non-numeric columns in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78a4222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:03.462986Z",
     "iopub.status.busy": "2022-11-16T07:30:03.462620Z",
     "iopub.status.idle": "2022-11-16T07:30:03.479880Z",
     "shell.execute_reply": "2022-11-16T07:30:03.479078Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.147396,
     "end_time": "2022-11-16T07:30:03.481587",
     "exception": false,
     "start_time": "2022-11-16T07:30:03.334191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      891      891\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7      691      646"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51900873",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.130336,
     "end_time": "2022-11-16T07:30:03.742805",
     "exception": false,
     "start_time": "2022-11-16T07:30:03.612469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Clearly we can't multiply strings like `male` or `S` by coefficients, so we need to replace those with numbers.\n",
    "\n",
    "We do that by creating new columns containing *dummy variables*. A dummy variable is a column that contains a `1` where a particular column contains a particular value, or a `0` otherwise. For instance, we could create a dummy variable for `Sex='male'`, which would be a new column containing `1` for rows where `Sex` is `'male'`, and 0 for rows where it isn't.\n",
    "\n",
    "Pandas can create these automatically using `get_dummies`, which also remove the original columns. We'll create dummy variables for `Pclass`, even although it's numeric, since the numbers `1`, `2`, and `3` correspond to first, second, and third class cabins - not to counts or measures that make sense to multiply by. We'll also create dummies for `Sex` and `Embarked` since we'll want to use those as predictors in our model. On the other hand, `Cabin`, `Name`, and `Ticket` have too many unique values for it to make sense creating dummy variables for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8df99ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:04.006166Z",
     "iopub.status.busy": "2022-11-16T07:30:04.005835Z",
     "iopub.status.idle": "2022-11-16T07:30:04.018157Z",
     "shell.execute_reply": "2022-11-16T07:30:04.017465Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.145991,
     "end_time": "2022-11-16T07:30:04.019931",
     "exception": false,
     "start_time": "2022-11-16T07:30:03.873940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67634c7",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.129812,
     "end_time": "2022-11-16T07:30:04.281378",
     "exception": false,
     "start_time": "2022-11-16T07:30:04.151566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that 5 columns have been added to the end -- one for each of the possible values of each of the three columns we requested, and that those three requested columns have been removed.\n",
    "\n",
    "Here's what the first few rows of those newly added columns look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a55c10",
   "metadata": {
    "papermill": {
     "duration": 0.129358,
     "end_time": "2022-11-16T07:30:04.542601",
     "exception": false,
     "start_time": "2022-11-16T07:30:04.413243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2a64d67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:04.810190Z",
     "iopub.status.busy": "2022-11-16T07:30:04.809530Z",
     "iopub.status.idle": "2022-11-16T07:30:04.819952Z",
     "shell.execute_reply": "2022-11-16T07:30:04.819451Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.14474,
     "end_time": "2022-11-16T07:30:04.821507",
     "exception": false,
     "start_time": "2022-11-16T07:30:04.676767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n",
       "0         1           0         0         0         1           0           0           1\n",
       "1         0           1         1         0         0           1           0           0\n",
       "2         0           1         0         0         1           0           0           1\n",
       "3         0           1         1         0         0           0           0           1\n",
       "4         1           0         0         0         1           0           0           1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "df[added_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a119ef84",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.131923,
     "end_time": "2022-11-16T07:30:05.082785",
     "exception": false,
     "start_time": "2022-11-16T07:30:04.950862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can create our independent (predictors) and dependent (target) variables. They both need to be PyTorch tensors. Our dependent variable is `Survived`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aadbb17e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:05.345475Z",
     "iopub.status.busy": "2022-11-16T07:30:05.344946Z",
     "iopub.status.idle": "2022-11-16T07:30:05.358830Z",
     "shell.execute_reply": "2022-11-16T07:30:05.357603Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.149341,
     "end_time": "2022-11-16T07:30:05.361120",
     "exception": false,
     "start_time": "2022-11-16T07:30:05.211779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "t_dep = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb4939e",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.129436,
     "end_time": "2022-11-16T07:30:05.622087",
     "exception": false,
     "start_time": "2022-11-16T07:30:05.492651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our independent variables are all the continuous variables of interest plus all the dummy variables we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "876bb6fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:05.887427Z",
     "iopub.status.busy": "2022-11-16T07:30:05.887170Z",
     "iopub.status.idle": "2022-11-16T07:30:05.986957Z",
     "shell.execute_reply": "2022-11-16T07:30:05.985853Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.234562,
     "end_time": "2022-11-16T07:30:05.989472",
     "exception": false,
     "start_time": "2022-11-16T07:30:05.754910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        ...,\n",
       "        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n",
    "\n",
    "t_indep = tensor(df[indep_cols].values, dtype=torch.float)\n",
    "t_indep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9a86b",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.129996,
     "end_time": "2022-11-16T07:30:06.250894",
     "exception": false,
     "start_time": "2022-11-16T07:30:06.120898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here's the number of rows and columns we have for our independent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c499f4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:06.538430Z",
     "iopub.status.busy": "2022-11-16T07:30:06.537988Z",
     "iopub.status.idle": "2022-11-16T07:30:06.542014Z",
     "shell.execute_reply": "2022-11-16T07:30:06.541561Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.139864,
     "end_time": "2022-11-16T07:30:06.544038",
     "exception": false,
     "start_time": "2022-11-16T07:30:06.404174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03401a7d",
   "metadata": {
    "papermill": {
     "duration": 0.132508,
     "end_time": "2022-11-16T07:30:06.808006",
     "exception": false,
     "start_time": "2022-11-16T07:30:06.675498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setting up a linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f742ea",
   "metadata": {
    "papermill": {
     "duration": 0.129287,
     "end_time": "2022-11-16T07:30:07.072097",
     "exception": false,
     "start_time": "2022-11-16T07:30:06.942810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we've got a matrix of independent variables and a dependent variable vector, we can work on calculating our predictions and our loss. In this section, we're going to manually do a single step of calculating predictions and loss for every row of our data.\n",
    "\n",
    "Our first model will be a simple linear model. We'll need a coefficient for each column in `t_indep`. We'll pick random numbers in the range `(-0.5,0.5)`, and set our manual seed so that my explanations in the prose in this notebook will be consistent with what you see when you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "708df393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:07.336210Z",
     "iopub.status.busy": "2022-11-16T07:30:07.335780Z",
     "iopub.status.idle": "2022-11-16T07:30:07.352071Z",
     "shell.execute_reply": "2022-11-16T07:30:07.351548Z"
    },
    "papermill": {
     "duration": 0.151636,
     "end_time": "2022-11-16T07:30:07.354265",
     "exception": false,
     "start_time": "2022-11-16T07:30:07.202629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(442)\n",
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "coeffs = torch.rand(n_coeff)-0.5\n",
    "coeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9409f11e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:07.620325Z",
     "iopub.status.busy": "2022-11-16T07:30:07.619897Z",
     "iopub.status.idle": "2022-11-16T07:30:07.624538Z",
     "shell.execute_reply": "2022-11-16T07:30:07.623573Z"
    },
    "papermill": {
     "duration": 0.14079,
     "end_time": "2022-11-16T07:30:07.626271",
     "exception": false,
     "start_time": "2022-11-16T07:30:07.485481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b738e9d",
   "metadata": {
    "papermill": {
     "duration": 0.132752,
     "end_time": "2022-11-16T07:30:07.891806",
     "exception": false,
     "start_time": "2022-11-16T07:30:07.759054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our predictions will be calculated by multiplying each row by the coefficients, and adding them up. One interesting point here is that we don't need a separate constant term (also known as a \"bias\" or \"intercept\" term), or a column of all `1`s to give the same effect has having a constant term. That's because our dummy variables already cover the entire dataset -- e.g. there's a column for \"male\" and a column for \"female\", and everyone in the dataset is in exactly one of these; therefore, we don't need a separate intercept term to cover rows that aren't otherwise part of a column.\n",
    "\n",
    "Here's what the multiplication looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7d67e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:08.159269Z",
     "iopub.status.busy": "2022-11-16T07:30:08.158823Z",
     "iopub.status.idle": "2022-11-16T07:30:08.162166Z",
     "shell.execute_reply": "2022-11-16T07:30:08.161440Z"
    },
    "papermill": {
     "duration": 0.140359,
     "end_time": "2022-11-16T07:30:08.164056",
     "exception": false,
     "start_time": "2022-11-16T07:30:08.023697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "check=t_indep*coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e4ee9e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:08.431121Z",
     "iopub.status.busy": "2022-11-16T07:30:08.430713Z",
     "iopub.status.idle": "2022-11-16T07:30:08.435576Z",
     "shell.execute_reply": "2022-11-16T07:30:08.434745Z"
    },
    "papermill": {
     "duration": 0.14077,
     "end_time": "2022-11-16T07:30:08.437474",
     "exception": false,
     "start_time": "2022-11-16T07:30:08.296704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ca4c4",
   "metadata": {
    "papermill": {
     "duration": 0.134037,
     "end_time": "2022-11-16T07:30:08.705541",
     "exception": false,
     "start_time": "2022-11-16T07:30:08.571504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see we've got a problem here. The sums of each row will be dominated by the first column, which is `Age`, since that's bigger on average than all the others.\n",
    "\n",
    "Let's make all the columns contain numbers from `0` to `1`, by dividing each column by its `max()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ac90715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:08.975051Z",
     "iopub.status.busy": "2022-11-16T07:30:08.974783Z",
     "iopub.status.idle": "2022-11-16T07:30:08.982088Z",
     "shell.execute_reply": "2022-11-16T07:30:08.981350Z"
    },
    "papermill": {
     "duration": 0.144295,
     "end_time": "2022-11-16T07:30:08.984196",
     "exception": false,
     "start_time": "2022-11-16T07:30:08.839901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5714ef08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:09.253250Z",
     "iopub.status.busy": "2022-11-16T07:30:09.252780Z",
     "iopub.status.idle": "2022-11-16T07:30:09.258893Z",
     "shell.execute_reply": "2022-11-16T07:30:09.258290Z"
    },
    "papermill": {
     "duration": 0.14317,
     "end_time": "2022-11-16T07:30:09.260465",
     "exception": false,
     "start_time": "2022-11-16T07:30:09.117295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4750, 0.1250, 0.0000, 0.6859, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.3250, 0.0000, 0.0000, 0.3507, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4375, 0.1250, 0.0000, 0.6395, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4375, 0.0000, 0.0000, 0.3530, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3000, 0.0000, 0.0000, 0.3600, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n",
       "        [0.6750, 0.0000, 0.0000, 0.6358, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.3125, 0.0000, 0.0000, 0.3342, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4875, 0.0000, 0.8333, 0.5456, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n",
       "        [0.3375, 0.0000, 0.0000, 0.4229, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.2375, 0.0000, 0.0000, 0.5502, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3000, 0.1250, 0.3333, 0.5122, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3250, 0.0000, 0.0000, 0.5502, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.4000, 0.0000, 0.0000, 0.3476, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56d7b725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:09.527126Z",
     "iopub.status.busy": "2022-11-16T07:30:09.526372Z",
     "iopub.status.idle": "2022-11-16T07:30:09.531851Z",
     "shell.execute_reply": "2022-11-16T07:30:09.531302Z"
    },
    "papermill": {
     "duration": 0.1406,
     "end_time": "2022-11-16T07:30:09.533424",
     "exception": false,
     "start_time": "2022-11-16T07:30:09.392824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9abde51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:09.802740Z",
     "iopub.status.busy": "2022-11-16T07:30:09.802313Z",
     "iopub.status.idle": "2022-11-16T07:30:09.808008Z",
     "shell.execute_reply": "2022-11-16T07:30:09.807231Z"
    },
    "papermill": {
     "duration": 0.142894,
     "end_time": "2022-11-16T07:30:09.809667",
     "exception": false,
     "start_time": "2022-11-16T07:30:09.666773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4750, 0.1250, 0.0000, 0.6859, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.3250, 0.0000, 0.0000, 0.3507, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4375, 0.1250, 0.0000, 0.6395, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4375, 0.0000, 0.0000, 0.3530, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3000, 0.0000, 0.0000, 0.3600, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n",
       "        [0.6750, 0.0000, 0.0000, 0.6358, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.3125, 0.0000, 0.0000, 0.3342, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4875, 0.0000, 0.8333, 0.5456, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n",
       "        [0.3375, 0.0000, 0.0000, 0.4229, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.2375, 0.0000, 0.0000, 0.5502, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3000, 0.1250, 0.3333, 0.5122, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3250, 0.0000, 0.0000, 0.5502, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.4000, 0.0000, 0.0000, 0.3476, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b25afeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:10.074466Z",
     "iopub.status.busy": "2022-11-16T07:30:10.074192Z",
     "iopub.status.idle": "2022-11-16T07:30:10.079911Z",
     "shell.execute_reply": "2022-11-16T07:30:10.078981Z"
    },
    "papermill": {
     "duration": 0.139533,
     "end_time": "2022-11-16T07:30:10.082207",
     "exception": false,
     "start_time": "2022-11-16T07:30:09.942674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd4dce",
   "metadata": {
    "papermill": {
     "duration": 0.134076,
     "end_time": "2022-11-16T07:30:10.348316",
     "exception": false,
     "start_time": "2022-11-16T07:30:10.214240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we see, that removes the problem of one column dominating all the others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4a3c3b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:10.616328Z",
     "iopub.status.busy": "2022-11-16T07:30:10.615920Z",
     "iopub.status.idle": "2022-11-16T07:30:10.622543Z",
     "shell.execute_reply": "2022-11-16T07:30:10.621569Z"
    },
    "papermill": {
     "duration": 0.142452,
     "end_time": "2022-11-16T07:30:10.625061",
     "exception": false,
     "start_time": "2022-11-16T07:30:10.482609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n",
       "        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2025,  0.0000,  0.0000, -0.0798, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1389,  0.0000,  0.0000, -0.0814, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n",
       "        [-0.3125,  0.0000,  0.0000, -0.1438, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        ...,\n",
       "        [-0.1447,  0.0000,  0.0000, -0.0756, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2257,  0.0000,  0.2008, -0.1234, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n",
       "        [-0.1562,  0.0000,  0.0000, -0.0956, -0.2632, -0.0000,  0.0000,  0.3136,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1099,  0.0000,  0.0000, -0.1244, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1389,  0.0173,  0.0803, -0.1158, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1504,  0.0000,  0.0000, -0.1244, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n",
       "        [-0.1852,  0.0000,  0.0000, -0.0786, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73eea1ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:10.897474Z",
     "iopub.status.busy": "2022-11-16T07:30:10.897225Z",
     "iopub.status.idle": "2022-11-16T07:30:10.904173Z",
     "shell.execute_reply": "2022-11-16T07:30:10.903012Z"
    },
    "papermill": {
     "duration": 0.145527,
     "end_time": "2022-11-16T07:30:10.905948",
     "exception": false,
     "start_time": "2022-11-16T07:30:10.760421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410991a4",
   "metadata": {
    "papermill": {
     "duration": 0.134489,
     "end_time": "2022-11-16T07:30:11.174699",
     "exception": false,
     "start_time": "2022-11-16T07:30:11.040210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "One thing you hopefully noticed is how amazingly cool this line of code is:\n",
    "\n",
    "    t_indep = t_indep / vals\n",
    "\n",
    "That is dividing a matrix by a vector -- what on earth does that mean?!? The trick here is that we're taking advantage of a technique in numpy and PyTorch (and many other languages, going all the way back to APL) called [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html). In short, this acts as if there's a separate copy of the vector for every row of the matrix, so it divides each row of the matrix by the vector. In practice, it doesn't actually make any copies, and does the whole thing in a highly optimized way, taking full advantage of modern CPUs (or, indeed, GPUs, if we're using them). Broadcasting is one of the most important techniques for making your code concise, maintainable, and fast, so it's well worth studying and practicing.\n",
    "\n",
    "We can now create predictions from our linear model, by adding up the rows of the product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "670fa04b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:11.445326Z",
     "iopub.status.busy": "2022-11-16T07:30:11.444924Z",
     "iopub.status.idle": "2022-11-16T07:30:11.452433Z",
     "shell.execute_reply": "2022-11-16T07:30:11.451586Z"
    },
    "papermill": {
     "duration": 0.146221,
     "end_time": "2022-11-16T07:30:11.454388",
     "exception": false,
     "start_time": "2022-11-16T07:30:11.308167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23844c",
   "metadata": {
    "papermill": {
     "duration": 0.135399,
     "end_time": "2022-11-16T07:30:11.725665",
     "exception": false,
     "start_time": "2022-11-16T07:30:11.590266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at the first few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c73303a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:11.998557Z",
     "iopub.status.busy": "2022-11-16T07:30:11.998075Z",
     "iopub.status.idle": "2022-11-16T07:30:12.005586Z",
     "shell.execute_reply": "2022-11-16T07:30:12.004834Z"
    },
    "papermill": {
     "duration": 0.145957,
     "end_time": "2022-11-16T07:30:12.007394",
     "exception": false,
     "start_time": "2022-11-16T07:30:11.861437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03855db6",
   "metadata": {
    "papermill": {
     "duration": 0.132492,
     "end_time": "2022-11-16T07:30:12.274955",
     "exception": false,
     "start_time": "2022-11-16T07:30:12.142463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Of course, these predictions aren't going to be any use, since our coefficients are random -- they're just a starting point for our gradient descent process.\n",
    "\n",
    "To do gradient descent, we need a loss function. Taking the average error of the rows (i.e. the absolute value of the difference between the prediction and the dependent) is generally a reasonable approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75cea134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:12.546615Z",
     "iopub.status.busy": "2022-11-16T07:30:12.546168Z",
     "iopub.status.idle": "2022-11-16T07:30:12.556127Z",
     "shell.execute_reply": "2022-11-16T07:30:12.555670Z"
    },
    "papermill": {
     "duration": 0.150223,
     "end_time": "2022-11-16T07:30:12.558127",
     "exception": false,
     "start_time": "2022-11-16T07:30:12.407904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(preds-t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a429170b",
   "metadata": {
    "papermill": {
     "duration": 0.137674,
     "end_time": "2022-11-16T07:30:12.829622",
     "exception": false,
     "start_time": "2022-11-16T07:30:12.691948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we've tested out a way of calculating predictions, and loss, let's pop them into functions to make life easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eff62bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:13.100852Z",
     "iopub.status.busy": "2022-11-16T07:30:13.100582Z",
     "iopub.status.idle": "2022-11-16T07:30:13.105068Z",
     "shell.execute_reply": "2022-11-16T07:30:13.104119Z"
    },
    "papermill": {
     "duration": 0.142821,
     "end_time": "2022-11-16T07:30:13.106898",
     "exception": false,
     "start_time": "2022-11-16T07:30:12.964077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\n",
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3c8c1",
   "metadata": {
    "papermill": {
     "duration": 0.13804,
     "end_time": "2022-11-16T07:30:13.382246",
     "exception": false,
     "start_time": "2022-11-16T07:30:13.244206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Doing a gradient descent step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df025c1",
   "metadata": {
    "papermill": {
     "duration": 0.134921,
     "end_time": "2022-11-16T07:30:13.654506",
     "exception": false,
     "start_time": "2022-11-16T07:30:13.519585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this section, we're going to do a single \"epoch\" of gradient descent manually. The only thing we're going to automate is calculating gradients, because let's face it that's pretty tedious and entirely pointless to do by hand! To get PyTorch to calculate gradients, we'll need to call `requires_grad_()` on our `coeffs` (if you're not sure why, review the previous notebook, [How does a neural net really work?](https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work), before continuing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65592c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:13.930424Z",
     "iopub.status.busy": "2022-11-16T07:30:13.929971Z",
     "iopub.status.idle": "2022-11-16T07:30:13.935290Z",
     "shell.execute_reply": "2022-11-16T07:30:13.934682Z"
    },
    "papermill": {
     "duration": 0.144668,
     "end_time": "2022-11-16T07:30:13.936859",
     "exception": false,
     "start_time": "2022-11-16T07:30:13.792191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31ed7239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:14.226678Z",
     "iopub.status.busy": "2022-11-16T07:30:14.226070Z",
     "iopub.status.idle": "2022-11-16T07:30:14.231643Z",
     "shell.execute_reply": "2022-11-16T07:30:14.231014Z"
    },
    "papermill": {
     "duration": 0.150786,
     "end_time": "2022-11-16T07:30:14.234016",
     "exception": false,
     "start_time": "2022-11-16T07:30:14.083230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bc202",
   "metadata": {
    "papermill": {
     "duration": 0.13761,
     "end_time": "2022-11-16T07:30:14.517379",
     "exception": false,
     "start_time": "2022-11-16T07:30:14.379769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now when we calculate our loss, PyTorch will keep track of all the steps, so we'll be able to get the gradients afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "180dd8aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:14.796180Z",
     "iopub.status.busy": "2022-11-16T07:30:14.795719Z",
     "iopub.status.idle": "2022-11-16T07:30:14.803986Z",
     "shell.execute_reply": "2022-11-16T07:30:14.802656Z"
    },
    "papermill": {
     "duration": 0.150057,
     "end_time": "2022-11-16T07:30:14.806328",
     "exception": false,
     "start_time": "2022-11-16T07:30:14.656271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609bf03",
   "metadata": {
    "papermill": {
     "duration": 0.135187,
     "end_time": "2022-11-16T07:30:15.084182",
     "exception": false,
     "start_time": "2022-11-16T07:30:14.948995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use `backward()` to ask PyTorch to calculate gradients now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2e63beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:15.360277Z",
     "iopub.status.busy": "2022-11-16T07:30:15.359830Z",
     "iopub.status.idle": "2022-11-16T07:30:15.373385Z",
     "shell.execute_reply": "2022-11-16T07:30:15.372499Z"
    },
    "papermill": {
     "duration": 0.154186,
     "end_time": "2022-11-16T07:30:15.375905",
     "exception": false,
     "start_time": "2022-11-16T07:30:15.221719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss.backward() #just used to tell PyTorch to calculate gradients??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce0ac17",
   "metadata": {
    "papermill": {
     "duration": 0.134732,
     "end_time": "2022-11-16T07:30:15.644975",
     "exception": false,
     "start_time": "2022-11-16T07:30:15.510243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73da82b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:15.920326Z",
     "iopub.status.busy": "2022-11-16T07:30:15.919258Z",
     "iopub.status.idle": "2022-11-16T07:30:15.926008Z",
     "shell.execute_reply": "2022-11-16T07:30:15.925481Z"
    },
    "papermill": {
     "duration": 0.145419,
     "end_time": "2022-11-16T07:30:15.927573",
     "exception": false,
     "start_time": "2022-11-16T07:30:15.782154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5deab",
   "metadata": {
    "papermill": {
     "duration": 0.136721,
     "end_time": "2022-11-16T07:30:16.202303",
     "exception": false,
     "start_time": "2022-11-16T07:30:16.065582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that each time we call `backward`, the gradients are actually *added* to whatever is in the `.grad` attribute. Let's try running the above steps again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "727b3238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:16.478841Z",
     "iopub.status.busy": "2022-11-16T07:30:16.478556Z",
     "iopub.status.idle": "2022-11-16T07:30:16.487270Z",
     "shell.execute_reply": "2022-11-16T07:30:16.486501Z"
    },
    "papermill": {
     "duration": 0.149029,
     "end_time": "2022-11-16T07:30:16.489380",
     "exception": false,
     "start_time": "2022-11-16T07:30:16.340351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0212,  0.0258, -0.0082, -0.0969,  0.4198, -0.4265, -0.2424, -0.0494,  0.2851, -0.3771, -0.0382,  0.4085])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980a41da",
   "metadata": {
    "papermill": {
     "duration": 0.135181,
     "end_time": "2022-11-16T07:30:16.762542",
     "exception": false,
     "start_time": "2022-11-16T07:30:16.627361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you see, our `.grad` values are have doubled. That's because it added the gradients a second time. For this reason, after we use the gradients to do a gradient descent step, we need to set them back to zero.\n",
    "\n",
    "We can now do one gradient descent step, and check that our loss decreases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "050abda6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:17.037678Z",
     "iopub.status.busy": "2022-11-16T07:30:17.037050Z",
     "iopub.status.idle": "2022-11-16T07:30:17.044388Z",
     "shell.execute_reply": "2022-11-16T07:30:17.042978Z"
    },
    "papermill": {
     "duration": 0.147668,
     "end_time": "2022-11-16T07:30:17.046606",
     "exception": false,
     "start_time": "2022-11-16T07:30:16.898938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4945)\n"
     ]
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward() #it adds coeffs.grad value to coeffs.grad that is why we need to make it 0.\n",
    "with torch.no_grad():\n",
    "    coeffs.sub_(coeffs.grad * 0.1) #subtracting from coeffs\n",
    "    coeffs.grad.zero_() #sets coeffs to 0.\n",
    "    print(calc_loss(coeffs, t_indep, t_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f527d8",
   "metadata": {
    "papermill": {
     "duration": 0.153176,
     "end_time": "2022-11-16T07:30:17.335345",
     "exception": false,
     "start_time": "2022-11-16T07:30:17.182169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that `a.sub_(b)` subtracts `b` from `a` in-place. In PyTorch, any method that ends in `_` changes its object in-place. Similarly, `a.zero_()` sets all elements of a tensor to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386751a",
   "metadata": {
    "papermill": {
     "duration": 0.136355,
     "end_time": "2022-11-16T07:30:17.614634",
     "exception": false,
     "start_time": "2022-11-16T07:30:17.478279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e28ddb",
   "metadata": {
    "papermill": {
     "duration": 0.137329,
     "end_time": "2022-11-16T07:30:17.890245",
     "exception": false,
     "start_time": "2022-11-16T07:30:17.752916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before we begin training our model, we'll need to ensure that we hold out a validation set for calculating our metrics (for details on this, see \"[Getting started with NLP for absolute beginners](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners#Test-and-validation-sets)\".\n",
    "\n",
    "There's lots of different ways we can do this. In the next notebook we'll be comparing our approach here to what the fastai library does, so we'll want to ensure we split the data in the same way. So let's use `RandomSplitter` to get indices that will split our data into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "238a1075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:18.169488Z",
     "iopub.status.busy": "2022-11-16T07:30:18.169110Z",
     "iopub.status.idle": "2022-11-16T07:30:19.319609Z",
     "shell.execute_reply": "2022-11-16T07:30:19.319061Z"
    },
    "papermill": {
     "duration": 1.292904,
     "end_time": "2022-11-16T07:30:19.321711",
     "exception": false,
     "start_time": "2022-11-16T07:30:18.028807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split,val_split=RandomSplitter(seed=42)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95394a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:19.598788Z",
     "iopub.status.busy": "2022-11-16T07:30:19.598399Z",
     "iopub.status.idle": "2022-11-16T07:30:19.602314Z",
     "shell.execute_reply": "2022-11-16T07:30:19.601830Z"
    },
    "papermill": {
     "duration": 0.144035,
     "end_time": "2022-11-16T07:30:19.603734",
     "exception": false,
     "start_time": "2022-11-16T07:30:19.459699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6ecdc",
   "metadata": {
    "papermill": {
     "duration": 0.140497,
     "end_time": "2022-11-16T07:30:19.881376",
     "exception": false,
     "start_time": "2022-11-16T07:30:19.740879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can apply those indicies to our independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36724280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:20.158893Z",
     "iopub.status.busy": "2022-11-16T07:30:20.158648Z",
     "iopub.status.idle": "2022-11-16T07:30:20.169162Z",
     "shell.execute_reply": "2022-11-16T07:30:20.168449Z"
    },
    "papermill": {
     "duration": 0.151487,
     "end_time": "2022-11-16T07:30:20.170807",
     "exception": false,
     "start_time": "2022-11-16T07:30:20.019320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep =  t_dep[trn_split],t_dep[val_split]\n",
    "len(trn_indep),len(val_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778add8",
   "metadata": {
    "papermill": {
     "duration": 0.137943,
     "end_time": "2022-11-16T07:30:20.447162",
     "exception": false,
     "start_time": "2022-11-16T07:30:20.309219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll create functions for the three things we did manually above: updating `coeffs`, doing one full gradient descent step, and initilising `coeffs` to random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffbbcee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:20.727969Z",
     "iopub.status.busy": "2022-11-16T07:30:20.727696Z",
     "iopub.status.idle": "2022-11-16T07:30:20.732716Z",
     "shell.execute_reply": "2022-11-16T07:30:20.731460Z"
    },
    "papermill": {
     "duration": 0.147469,
     "end_time": "2022-11-16T07:30:20.734733",
     "exception": false,
     "start_time": "2022-11-16T07:30:20.587264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs,lr):\n",
    "    coeffs.sub_(coeffs.grad*lr)\n",
    "    coeffs.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "658728c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:21.016374Z",
     "iopub.status.busy": "2022-11-16T07:30:21.016092Z",
     "iopub.status.idle": "2022-11-16T07:30:21.021032Z",
     "shell.execute_reply": "2022-11-16T07:30:21.019979Z"
    },
    "papermill": {
     "duration": 0.148486,
     "end_time": "2022-11-16T07:30:21.022879",
     "exception": false,
     "start_time": "2022-11-16T07:30:20.874393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_epoch(coeffs,lr):\n",
    "    loss = calc_loss(coeffs,trn_indep,trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs,lr) #don't understand torch.no_grad()\n",
    "    print(f\"Loss {loss:.3f}\", end=\"; \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0c7c530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:21.300135Z",
     "iopub.status.busy": "2022-11-16T07:30:21.299909Z",
     "iopub.status.idle": "2022-11-16T07:30:21.304640Z",
     "shell.execute_reply": "2022-11-16T07:30:21.303283Z"
    },
    "papermill": {
     "duration": 0.146307,
     "end_time": "2022-11-16T07:30:21.306679",
     "exception": false,
     "start_time": "2022-11-16T07:30:21.160372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff)-0.5) #n_coeffs is the number of paras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d09e9",
   "metadata": {
    "papermill": {
     "duration": 0.13878,
     "end_time": "2022-11-16T07:30:21.583449",
     "exception": false,
     "start_time": "2022-11-16T07:30:21.444669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now use these functions to train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4574973a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:21.863171Z",
     "iopub.status.busy": "2022-11-16T07:30:21.862904Z",
     "iopub.status.idle": "2022-11-16T07:30:21.868160Z",
     "shell.execute_reply": "2022-11-16T07:30:21.867029Z"
    },
    "papermill": {
     "duration": 0.148518,
     "end_time": "2022-11-16T07:30:21.870296",
     "exception": false,
     "start_time": "2022-11-16T07:30:21.721778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(epochs=30,lr=0.01):\n",
    "    torch.manual_seed(442)\n",
    "    coeffs = init_coeffs()\n",
    "    coeffs.requires_grad_()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5116cd",
   "metadata": {
    "papermill": {
     "duration": 0.140307,
     "end_time": "2022-11-16T07:30:22.150199",
     "exception": false,
     "start_time": "2022-11-16T07:30:22.009892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's try it. Our loss will print at the end of every step, so we hope we'll see it going down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29400102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:22.430534Z",
     "iopub.status.busy": "2022-11-16T07:30:22.430269Z",
     "iopub.status.idle": "2022-11-16T07:30:23.207465Z",
     "shell.execute_reply": "2022-11-16T07:30:23.206445Z"
    },
    "papermill": {
     "duration": 0.91904,
     "end_time": "2022-11-16T07:30:23.209791",
     "exception": false,
     "start_time": "2022-11-16T07:30:22.290751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.536; Loss 0.492; Loss 0.458; Loss 0.432; Loss 0.432; Loss 0.366; Loss 0.359; Loss 0.369; Loss 0.308; Loss 0.307; Loss 0.328; Loss 0.342; Loss 0.297; Loss 0.321; Loss 0.310; Loss 0.347; Loss 0.294; Loss 0.314; Loss 0.315; Loss 0.355; Loss 0.308; Loss 0.338; Loss 0.301; Loss 0.333; Loss 0.310; Loss 0.366; Loss 0.299; Loss 0.332; Loss 0.288; Loss 0.330; Loss 0.313; Loss 0.375; Loss 0.301; Loss 0.333; Loss 0.284; Loss 0.326; Loss 0.306; Loss 0.379; Loss 0.301; Loss 0.337; Loss 0.280; Loss 0.328; Loss 0.302; Loss 0.373; Loss 0.302; Loss 0.352; Loss 0.274; Loss 0.301; Loss 0.299; Loss 0.391; Loss 0.307; Loss 0.350; Loss 0.285; Loss 0.329; Loss 0.285; Loss 0.363; Loss 0.313; Loss 0.367; Loss 0.274; Loss 0.302; Loss 0.286; Loss 0.387; Loss 0.310; Loss 0.360; Loss 0.287; Loss 0.321; Loss 0.279; Loss 0.353; Loss 0.326; Loss 0.369; Loss 0.279; Loss 0.315; Loss 0.274; Loss 0.362; Loss 0.333; Loss 0.364; Loss 0.278; Loss 0.313; Loss 0.280; Loss 0.374; Loss 0.320; Loss 0.365; Loss 0.276; Loss 0.311; Loss 0.276; Loss 0.369; Loss 0.326; Loss 0.364; Loss 0.277; Loss 0.315; Loss 0.279; Loss 0.378; Loss 0.316; Loss 0.367; Loss 0.274; Loss 0.309; Loss 0.276; Loss 0.370; Loss 0.326; Loss 0.364; Loss 0.280; Loss 0.319; Loss 0.278; Loss 0.365; Loss 0.324; Loss 0.364; Loss 0.273; Loss 0.310; Loss 0.277; Loss 0.373; Loss 0.322; Loss 0.366; Loss 0.279; Loss 0.318; Loss 0.275; Loss 0.360; Loss 0.327; Loss 0.365; Loss 0.275; Loss 0.311; Loss 0.275; Loss 0.368; Loss 0.327; Loss 0.367; Loss 0.279; Loss 0.316; Loss 0.274; Loss 0.359; Loss 0.328; Loss 0.366; Loss 0.275; Loss 0.311; Loss 0.273; Loss 0.368; Loss 0.326; Loss 0.368; Loss 0.280; Loss 0.318; Loss 0.272; Loss 0.357; Loss 0.329; Loss 0.367; Loss 0.275; Loss 0.311; Loss 0.274; Loss 0.365; Loss 0.327; Loss 0.368; Loss 0.279; Loss 0.313; Loss 0.271; Loss 0.359; Loss 0.330; Loss 0.367; Loss 0.279; Loss 0.317; Loss 0.272; Loss 0.360; Loss 0.327; Loss 0.367; Loss 0.275; Loss 0.311; Loss 0.274; Loss 0.373; Loss 0.319; Loss 0.366; Loss 0.276; Loss 0.313; Loss 0.275; Loss 0.372; Loss 0.318; Loss 0.366; Loss 0.277; Loss 0.312; Loss 0.272; Loss 0.372; Loss 0.318; Loss 0.367; Loss 0.277; Loss 0.313; Loss 0.274; Loss 0.372; Loss 0.318; Loss 0.366; Loss 0.275; Loss 0.312; Loss 0.273; Loss 0.373; Loss 0.317; Loss 0.369; Loss 0.277; Loss 0.312; Loss 0.272; Loss 0.370; Loss 0.319; Loss 0.369; Loss 0.277; Loss 0.312; Loss 0.273; Loss 0.370; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.311; Loss 0.276; Loss 0.371; Loss 0.316; Loss 0.368; Loss 0.276; Loss 0.312; Loss 0.271; Loss 0.370; Loss 0.317; Loss 0.369; Loss 0.276; Loss 0.312; Loss 0.270; Loss 0.367; Loss 0.321; Loss 0.369; Loss 0.277; Loss 0.312; Loss 0.269; Loss 0.366; Loss 0.322; Loss 0.368; Loss 0.277; Loss 0.312; Loss 0.269; Loss 0.366; Loss 0.321; Loss 0.369; Loss 0.277; Loss 0.311; Loss 0.271; Loss 0.367; Loss 0.321; Loss 0.367; Loss 0.276; Loss 0.312; Loss 0.273; Loss 0.370; Loss 0.316; Loss 0.369; Loss 0.276; Loss 0.312; Loss 0.269; Loss 0.365; Loss 0.322; Loss 0.367; Loss 0.276; Loss 0.311; Loss 0.273; Loss 0.370; Loss 0.317; Loss 0.369; Loss 0.276; Loss 0.311; Loss 0.271; Loss 0.368; Loss 0.319; Loss 0.367; Loss 0.276; Loss 0.312; Loss 0.272; Loss 0.369; Loss 0.317; Loss 0.368; Loss 0.275; Loss 0.310; Loss 0.272; Loss 0.369; Loss 0.318; Loss 0.368; Loss 0.277; Loss 0.313; Loss 0.273; Loss 0.367; Loss 0.315; Loss 0.369; Loss 0.276; Loss 0.313; Loss 0.272; Loss 0.366; Loss 0.317; Loss 0.368; Loss 0.276; Loss 0.313; Loss 0.272; Loss 0.366; Loss 0.319; Loss 0.366; Loss 0.274; Loss 0.311; Loss 0.274; Loss 0.369; Loss 0.316; Loss 0.368; Loss 0.277; Loss 0.313; Loss 0.272; Loss 0.362; Loss 0.320; Loss 0.366; Loss 0.276; Loss 0.315; Loss 0.272; Loss 0.364; Loss 0.319; Loss 0.367; Loss 0.275; Loss 0.313; Loss 0.274; Loss 0.369; Loss 0.315; Loss 0.367; Loss 0.275; Loss 0.313; Loss 0.273; Loss 0.367; Loss 0.316; Loss 0.368; Loss 0.276; Loss 0.314; Loss 0.271; Loss 0.361; Loss 0.321; Loss 0.367; Loss 0.275; Loss 0.314; Loss 0.273; Loss 0.365; Loss 0.318; Loss 0.367; Loss 0.274; Loss 0.313; Loss 0.274; Loss 0.368; Loss 0.316; Loss 0.367; Loss 0.274; Loss 0.313; Loss 0.274; Loss 0.370; Loss 0.314; Loss 0.364; Loss 0.274; Loss 0.314; Loss 0.276; Loss 0.369; Loss 0.313; Loss 0.365; Loss 0.275; Loss 0.315; Loss 0.273; Loss 0.368; Loss 0.314; Loss 0.368; Loss 0.276; Loss 0.315; Loss 0.272; Loss 0.360; Loss 0.321; Loss 0.367; Loss 0.275; Loss 0.313; Loss 0.273; Loss 0.367; Loss 0.315; Loss 0.367; Loss 0.275; Loss 0.315; Loss 0.272; Loss 0.360; Loss 0.321; Loss 0.366; Loss 0.274; Loss 0.314; Loss 0.272; Loss 0.366; Loss 0.316; Loss 0.367; Loss 0.275; Loss 0.314; Loss 0.272; Loss 0.366; Loss 0.316; Loss 0.367; Loss 0.275; Loss 0.315; Loss 0.272; Loss 0.360; Loss 0.321; Loss 0.367; Loss 0.275; Loss 0.314; Loss 0.273; Loss 0.366; Loss 0.316; Loss 0.367; Loss 0.275; Loss 0.315; Loss 0.272; Loss 0.361; Loss 0.320; Loss 0.367; Loss 0.274; Loss 0.315; Loss 0.272; Loss 0.366; Loss 0.316; Loss 0.366; Loss 0.275; Loss 0.315; Loss 0.272; Loss 0.361; Loss 0.320; Loss 0.367; Loss 0.275; Loss 0.314; Loss 0.272; Loss 0.366; Loss 0.315; Loss 0.366; Loss 0.276; Loss 0.319; Loss 0.271; Loss 0.355; Loss 0.320; Loss 0.367; Loss 0.276; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.322; Loss 0.365; Loss 0.275; Loss 0.313; Loss 0.274; Loss 0.364; Loss 0.318; Loss 0.365; Loss 0.276; Loss 0.318; Loss 0.271; Loss 0.357; Loss 0.317; Loss 0.368; Loss 0.276; Loss 0.315; Loss 0.271; Loss 0.356; Loss 0.319; Loss 0.369; Loss 0.275; Loss 0.316; Loss 0.272; Loss 0.359; Loss 0.320; Loss 0.366; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.367; Loss 0.276; Loss 0.318; Loss 0.271; Loss 0.354; Loss 0.316; Loss 0.368; Loss 0.276; Loss 0.320; Loss 0.269; Loss 0.354; Loss 0.315; Loss 0.369; Loss 0.276; Loss 0.321; Loss 0.269; Loss 0.342; Loss 0.316; Loss 0.374; Loss 0.285; Loss 0.328; Loss 0.264; Loss 0.324; Loss 0.320; Loss 0.374; Loss 0.298; Loss 0.354; Loss 0.265; Loss 0.306; Loss 0.284; Loss 0.381; Loss 0.305; Loss 0.364; Loss 0.279; Loss 0.324; Loss 0.270; Loss 0.341; Loss 0.312; Loss 0.375; Loss 0.286; Loss 0.329; Loss 0.265; Loss 0.322; Loss 0.320; Loss 0.374; Loss 0.298; Loss 0.353; Loss 0.264; Loss 0.302; Loss 0.290; Loss 0.386; Loss 0.301; Loss 0.359; Loss 0.280; Loss 0.325; Loss 0.272; Loss 0.344; Loss 0.312; Loss 0.374; Loss 0.281; Loss 0.325; Loss 0.265; Loss 0.329; Loss 0.320; Loss 0.373; Loss 0.291; Loss 0.339; Loss 0.269; Loss 0.324; Loss 0.300; Loss 0.382; Loss 0.294; Loss 0.352; Loss 0.260; Loss 0.283; Loss 0.306; Loss 0.387; Loss 0.303; Loss 0.357; Loss 0.285; Loss 0.325; Loss 0.281; Loss 0.359; Loss 0.299; Loss 0.364; Loss 0.279; Loss 0.324; Loss 0.266; Loss 0.330; Loss 0.324; Loss 0.372; Loss 0.290; Loss 0.338; Loss 0.267; Loss 0.324; Loss 0.306; Loss 0.383; Loss 0.292; Loss 0.329; Loss 0.264; Loss 0.319; Loss 0.319; Loss 0.375; Loss 0.291; Loss 0.347; Loss 0.270; Loss 0.321; Loss 0.285; Loss 0.385; Loss 0.295; Loss 0.361; Loss 0.273; Loss 0.320; Loss 0.269; Loss 0.360; Loss 0.321; Loss 0.367; Loss 0.275; Loss 0.318; Loss 0.268; Loss 0.355; Loss 0.319; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.358; Loss 0.317; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.317; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.271; Loss 0.357; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.356; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.358; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.316; Loss 0.271; Loss 0.357; Loss 0.317; Loss 0.368; Loss 0.276; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.367; Loss 0.276; Loss 0.316; Loss 0.270; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.323; Loss 0.366; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.319; Loss 0.367; Loss 0.276; Loss 0.318; Loss 0.269; Loss 0.351; Loss 0.314; Loss 0.371; Loss 0.278; Loss 0.322; Loss 0.268; Loss 0.341; Loss 0.315; Loss 0.375; Loss 0.286; Loss 0.329; Loss 0.265; Loss 0.323; Loss 0.317; Loss 0.376; Loss 0.298; Loss 0.353; Loss 0.263; Loss 0.295; Loss 0.298; Loss 0.386; Loss 0.301; Loss 0.356; Loss 0.282; Loss 0.326; Loss 0.276; Loss 0.347; Loss 0.307; Loss 0.370; Loss 0.279; Loss 0.322; Loss 0.268; Loss 0.333; Loss 0.320; Loss 0.372; Loss 0.290; Loss 0.335; Loss 0.268; Loss 0.325; Loss 0.307; Loss 0.382; Loss 0.293; Loss 0.337; Loss 0.260; Loss 0.313; Loss 0.306; Loss 0.387; Loss 0.293; Loss 0.350; Loss 0.269; Loss 0.319; Loss 0.284; Loss 0.383; Loss 0.297; Loss 0.364; Loss 0.274; Loss 0.320; Loss 0.270; Loss 0.358; Loss 0.321; Loss 0.367; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.369; Loss 0.274; Loss 0.316; Loss 0.271; Loss 0.359; Loss 0.320; Loss 0.368; Loss 0.276; Loss 0.318; Loss 0.270; Loss 0.354; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.358; Loss 0.317; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.356; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.317; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.269; Loss 0.357; Loss 0.322; Loss 0.366; Loss 0.275; Loss 0.317; Loss 0.272; Loss 0.356; Loss 0.318; Loss 0.367; Loss 0.276; Loss 0.316; Loss 0.271; Loss 0.357; Loss 0.318; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.269; Loss 0.352; Loss 0.317; Loss 0.371; Loss 0.277; Loss 0.320; Loss 0.270; Loss 0.353; Loss 0.311; Loss 0.368; Loss 0.277; Loss 0.322; Loss 0.267; Loss 0.335; Loss 0.319; Loss 0.373; Loss 0.289; Loss 0.330; Loss 0.269; Loss 0.325; Loss 0.313; Loss 0.379; Loss 0.293; Loss 0.344; Loss 0.257; Loss 0.281; Loss 0.312; Loss 0.387; Loss 0.304; Loss 0.360; Loss 0.289; Loss 0.337; Loss 0.270; Loss 0.323; Loss 0.305; Loss 0.382; Loss 0.294; Loss 0.345; Loss 0.257; Loss 0.271; Loss 0.313; Loss 0.388; Loss 0.306; Loss 0.361; Loss 0.290; Loss 0.337; Loss 0.273; Loss 0.327; Loss 0.302; Loss 0.376; Loss 0.295; Loss 0.340; Loss 0.261; Loss 0.308; Loss 0.303; Loss 0.386; Loss 0.297; Loss 0.358; Loss 0.277; Loss 0.323; Loss 0.269; Loss 0.346; Loss 0.313; Loss 0.376; Loss 0.283; Loss 0.326; Loss 0.264; Loss 0.329; Loss 0.320; Loss 0.373; Loss 0.291; Loss 0.343; Loss 0.266; Loss 0.316; Loss 0.292; Loss 0.388; Loss 0.294; Loss 0.356; Loss 0.273; Loss 0.322; Loss 0.271; Loss 0.363; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.358; Loss 0.322; Loss 0.366; Loss 0.276; Loss 0.318; Loss 0.270; Loss 0.354; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.358; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.316; Loss 0.271; Loss 0.355; Loss 0.319; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.269; Loss 0.355; Loss 0.319; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.269; Loss 0.355; Loss 0.320; Loss 0.367; Loss 0.275; Loss 0.316; Loss 0.271; Loss 0.358; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.317; Loss 0.272; Loss 0.358; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.316; Loss 0.271; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.367; Loss 0.276; Loss 0.316; Loss 0.270; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.270; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.357; Loss 0.322; Loss 0.365; Loss 0.274; Loss 0.317; Loss 0.273; Loss 0.361; Loss 0.318; Loss 0.366; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.355; Loss 0.318; Loss 0.367; Loss 0.276; Loss 0.318; Loss 0.268; Loss 0.352; Loss 0.318; Loss 0.370; Loss 0.278; Loss 0.321; Loss 0.269; Loss 0.350; Loss 0.314; Loss 0.369; Loss 0.278; Loss 0.321; Loss 0.269; Loss 0.340; Loss 0.315; Loss 0.374; Loss 0.287; Loss 0.329; Loss 0.265; Loss 0.321; Loss 0.319; Loss 0.375; Loss 0.299; Loss 0.357; Loss 0.265; Loss 0.298; Loss 0.289; Loss 0.383; Loss 0.305; Loss 0.361; Loss 0.279; Loss 0.324; Loss 0.272; Loss 0.344; Loss 0.313; Loss 0.373; Loss 0.283; Loss 0.326; Loss 0.266; Loss 0.328; Loss 0.317; Loss 0.375; Loss 0.290; Loss 0.331; Loss 0.271; Loss 0.325; Loss 0.309; Loss 0.381; Loss 0.294; Loss 0.344; Loss 0.257; Loss 0.281; Loss 0.314; Loss 0.386; Loss 0.305; Loss 0.359; Loss 0.287; Loss 0.334; Loss 0.273; Loss 0.328; Loss 0.306; Loss 0.378; Loss 0.293; Loss 0.337; Loss 0.261; Loss 0.314; Loss 0.306; Loss 0.387; Loss 0.293; Loss 0.350; Loss 0.269; Loss 0.319; Loss 0.285; Loss 0.383; Loss 0.297; Loss 0.363; Loss 0.273; Loss 0.317; Loss 0.271; Loss 0.364; Loss 0.317; Loss 0.370; Loss 0.274; Loss 0.317; Loss 0.270; Loss 0.357; Loss 0.317; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.359; Loss 0.316; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.359; Loss 0.316; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.357; Loss 0.317; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.269; Loss 0.356; Loss 0.319; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.357; Loss 0.317; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.317; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.358; Loss 0.321; Loss 0.367; Loss 0.276; Loss 0.318; Loss 0.270; Loss 0.352; Loss 0.316; Loss 0.369; Loss 0.276; Loss 0.321; Loss 0.269; Loss 0.355; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.316; Loss 0.272; Loss 0.358; Loss 0.316; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.356; Loss 0.317; Loss 0.367; Loss 0.276; Loss 0.317; Loss 0.269; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.355; Loss 0.317; Loss 0.368; Loss 0.276; Loss 0.316; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.322; Loss 0.365; Loss 0.274; Loss 0.317; Loss 0.272; Loss 0.357; Loss 0.318; Loss 0.367; Loss 0.276; Loss 0.317; Loss 0.270; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.276; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.315; Loss 0.368; Loss 0.275; Loss 0.319; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.269; Loss 0.355; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.323; Loss 0.365; Loss 0.274; Loss 0.316; Loss 0.273; Loss 0.360; Loss 0.318; Loss 0.366; Loss 0.275; Loss 0.317; Loss 0.272; Loss 0.356; Loss 0.317; Loss 0.367; Loss 0.276; Loss 0.318; Loss 0.271; Loss 0.355; Loss 0.315; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.272; Loss 0.356; Loss 0.318; Loss 0.367; Loss 0.274; Loss 0.317; Loss 0.272; Loss 0.357; Loss 0.317; Loss 0.367; Loss 0.276; Loss 0.319; Loss 0.270; Loss 0.355; Loss 0.314; Loss 0.368; Loss 0.276; Loss 0.320; Loss 0.270; Loss 0.355; Loss 0.314; Loss 0.369; Loss 0.276; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.276; Loss 0.316; Loss 0.270; Loss 0.356; Loss 0.318; Loss 0.367; Loss 0.276; Loss 0.320; Loss 0.269; Loss 0.353; Loss 0.314; Loss 0.370; Loss 0.278; Loss 0.322; Loss 0.269; Loss 0.334; Loss 0.318; Loss 0.374; Loss 0.288; Loss 0.328; Loss 0.268; Loss 0.326; Loss 0.315; Loss 0.377; Loss 0.289; Loss 0.329; Loss 0.270; Loss 0.326; Loss 0.311; Loss 0.380; Loss 0.293; Loss 0.343; Loss 0.259; Loss 0.295; Loss 0.310; Loss 0.390; Loss 0.298; Loss 0.352; Loss 0.283; Loss 0.328; Loss 0.278; Loss 0.359; Loss 0.306; Loss 0.364; Loss 0.274; Loss 0.316; Loss 0.273; Loss 0.361; Loss 0.318; Loss 0.367; Loss 0.274; Loss 0.318; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.356; Loss 0.317; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.357; Loss 0.322; Loss 0.365; Loss 0.274; Loss 0.316; Loss 0.272; Loss 0.360; Loss 0.319; Loss 0.367; Loss 0.274; Loss 0.318; Loss 0.272; Loss 0.356; Loss 0.318; Loss 0.367; Loss 0.274; Loss 0.316; Loss 0.272; Loss 0.361; Loss 0.318; Loss 0.366; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.317; Loss 0.367; Loss 0.274; Loss 0.317; Loss 0.272; Loss 0.359; Loss 0.316; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.356; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.356; Loss 0.316; Loss 0.367; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.317; Loss 0.368; Loss 0.276; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.317; Loss 0.367; Loss 0.276; Loss 0.320; Loss 0.269; Loss 0.351; Loss 0.314; Loss 0.370; Loss 0.278; Loss 0.322; Loss 0.268; Loss 0.332; Loss 0.320; Loss 0.372; Loss 0.290; Loss 0.335; Loss 0.268; Loss 0.325; Loss 0.306; Loss 0.382; Loss 0.293; Loss 0.337; Loss 0.261; Loss 0.313; Loss 0.306; Loss 0.387; Loss 0.293; Loss 0.352; Loss 0.269; Loss 0.319; Loss 0.282; Loss 0.380; Loss 0.300; Loss 0.362; Loss 0.274; Loss 0.320; Loss 0.270; Loss 0.358; Loss 0.321; Loss 0.367; Loss 0.276; Loss 0.319; Loss 0.269; Loss 0.352; Loss 0.319; Loss 0.369; Loss 0.276; Loss 0.321; Loss 0.269; Loss 0.344; Loss 0.314; Loss 0.376; Loss 0.284; Loss 0.327; Loss 0.264; Loss 0.329; Loss 0.320; Loss 0.373; Loss 0.290; Loss 0.339; Loss 0.268; Loss 0.323; Loss 0.304; Loss 0.381; Loss 0.294; Loss 0.341; Loss 0.262; Loss 0.311; Loss 0.301; Loss 0.387; Loss 0.294; Loss 0.356; Loss 0.277; Loss 0.324; Loss 0.268; Loss 0.346; Loss 0.316; Loss 0.374; Loss 0.280; Loss 0.326; Loss 0.266; Loss 0.328; Loss 0.322; Loss 0.374; Loss 0.291; Loss 0.340; Loss 0.266; Loss 0.319; Loss 0.295; Loss 0.390; Loss 0.292; Loss 0.350; Loss 0.266; Loss 0.312; Loss 0.286; Loss 0.389; Loss 0.298; Loss 0.364; Loss 0.278; Loss 0.324; Loss 0.265; Loss 0.331; Loss 0.321; Loss 0.374; Loss 0.290; Loss 0.341; Loss 0.266; Loss 0.325; Loss 0.303; Loss 0.381; Loss 0.293; Loss 0.335; Loss 0.262; Loss 0.317; Loss 0.316; Loss 0.378; Loss 0.290; Loss 0.337; Loss 0.270; Loss 0.327; Loss 0.307; Loss 0.380; Loss 0.285; Loss 0.330; Loss 0.264; Loss 0.327; Loss 0.317; Loss 0.376; Loss 0.290; Loss 0.336; Loss 0.268; Loss 0.326; Loss 0.308; Loss 0.381; Loss 0.293; Loss 0.336; Loss 0.258; Loss 0.309; Loss 0.311; Loss 0.386; Loss 0.295; Loss 0.358; Loss 0.279; Loss 0.324; Loss 0.267; Loss 0.342; Loss 0.314; Loss 0.377; Loss 0.286; Loss 0.329; Loss 0.264; Loss 0.322; Loss 0.319; Loss 0.377; Loss 0.298; Loss 0.354; Loss 0.264; Loss 0.301; Loss 0.291; Loss 0.389; Loss 0.300; Loss 0.359; Loss 0.280; Loss 0.325; Loss 0.272; Loss 0.343; Loss 0.312; Loss 0.375; Loss 0.285; Loss 0.327; Loss 0.264; Loss 0.327; Loss 0.318; Loss 0.375; Loss 0.290; Loss 0.334; Loss 0.269; Loss 0.325; Loss 0.308; Loss 0.381; Loss 0.293; Loss 0.344; Loss 0.257; Loss 0.278; Loss 0.316; Loss 0.384; Loss 0.308; Loss 0.360; Loss 0.290; Loss 0.336; Loss 0.269; Loss 0.323; Loss 0.307; Loss 0.382; Loss 0.293; Loss 0.331; Loss 0.263; Loss 0.316; Loss 0.319; Loss 0.375; Loss 0.294; Loss 0.357; Loss 0.272; Loss 0.317; Loss 0.272; Loss 0.367; Loss 0.318; Loss 0.366; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.368; Loss 0.276; Loss 0.318; Loss 0.269; Loss 0.354; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.270; Loss 0.359; Loss 0.323; Loss 0.365; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.276; Loss 0.317; Loss 0.270; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.276; Loss 0.316; Loss 0.270; Loss 0.356; Loss 0.323; Loss 0.365; Loss 0.275; Loss 0.316; Loss 0.272; Loss 0.358; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.316; Loss 0.272; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.271; Loss 0.356; Loss 0.319; Loss 0.367; Loss 0.276; Loss 0.317; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.270; Loss 0.356; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.358; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.316; Loss 0.272; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.358; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.316; Loss 0.272; Loss 0.355; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.272; Loss 0.357; Loss 0.317; Loss 0.367; Loss 0.276; Loss 0.317; Loss 0.269; Loss 0.354; Loss 0.319; Loss 0.368; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.318; Loss 0.366; Loss 0.274; Loss 0.316; Loss 0.273; Loss 0.361; Loss 0.317; Loss 0.367; Loss 0.274; Loss 0.318; Loss 0.271; Loss 0.357; Loss 0.317; Loss 0.368; Loss 0.276; Loss 0.318; Loss 0.269; Loss 0.356; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.317; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.271; Loss 0.358; Loss 0.321; Loss 0.367; Loss 0.275; Loss 0.318; Loss 0.271; Loss 0.356; Loss 0.317; Loss 0.367; Loss 0.276; Loss 0.317; Loss 0.270; Loss 0.356; Loss 0.317; Loss 0.367; Loss 0.276; Loss 0.317; Loss 0.269; Loss 0.351; Loss 0.318; Loss 0.369; Loss 0.278; Loss 0.322; Loss 0.268; Loss 0.340; Loss 0.314; Loss 0.375; Loss 0.286; Loss 0.329; Loss 0.265; Loss 0.322; Loss 0.320; Loss 0.373; Loss 0.299; Loss 0.355; Loss 0.264; Loss 0.301; Loss 0.291; Loss 0.386; Loss 0.301; Loss 0.359; Loss 0.278; Loss 0.324; Loss 0.274; Loss 0.350; Loss 0.307; Loss 0.372; Loss 0.281; Loss 0.326; Loss 0.267; Loss 0.327; Loss 0.319; Loss 0.374; Loss 0.291; Loss 0.335; Loss 0.270; Loss 0.324; Loss 0.307; Loss 0.380; Loss 0.293; Loss 0.336; Loss 0.260; Loss 0.313; Loss 0.308; Loss 0.388; Loss 0.293; Loss 0.350; Loss 0.270; Loss 0.320; Loss 0.285; Loss 0.382; Loss 0.297; Loss 0.362; Loss 0.273; Loss 0.317; Loss 0.272; Loss 0.367; Loss 0.313; Loss 0.366; Loss 0.276; Loss 0.322; Loss 0.268; Loss 0.351; Loss 0.314; Loss 0.371; Loss 0.278; Loss 0.323; Loss 0.267; Loss 0.333; Loss 0.320; Loss 0.372; Loss 0.290; Loss 0.331; Loss 0.270; Loss 0.326; Loss 0.311; Loss 0.379; Loss 0.287; Loss 0.329; Loss 0.268; Loss 0.327; Loss 0.312; Loss 0.380; Loss 0.293; Loss 0.345; Loss 0.258; Loss 0.286; Loss 0.311; Loss 0.390; Loss 0.302; Loss 0.357; Loss 0.286; Loss 0.326; Loss 0.279; Loss 0.353; Loss 0.300; Loss 0.365; Loss 0.279; Loss 0.324; Loss 0.266; Loss 0.329; Loss 0.323; Loss 0.373; Loss 0.294; Loss 0.345; Loss 0.266; Loss 0.316; Loss 0.291; Loss 0.389; Loss 0.294; Loss 0.351; Loss 0.266; Loss 0.315; Loss 0.285; Loss 0.388; Loss 0.296; Loss 0.362; Loss 0.275; Loss 0.323; Loss 0.267; Loss 0.355; Loss 0.318; Loss 0.370; Loss 0.278; Loss 0.322; Loss 0.267; Loss 0.340; Loss 0.314; Loss 0.376; Loss 0.286; Loss 0.328; Loss 0.264; Loss 0.327; Loss 0.318; Loss 0.374; Loss 0.293; Loss 0.344; Loss 0.265; Loss 0.316; Loss 0.292; Loss 0.388; Loss 0.294; Loss 0.356; Loss 0.272; Loss 0.319; Loss 0.271; Loss 0.367; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.357; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.270; Loss 0.358; Loss 0.323; Loss 0.366; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.269; Loss 0.357; Loss 0.318; Loss 0.369; Loss 0.276; Loss 0.318; Loss 0.269; Loss 0.356; Loss 0.319; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.318; Loss 0.368; Loss 0.275; Loss 0.317; Loss 0.272; Loss 0.358; Loss 0.321; Loss 0.366; Loss 0.275; Loss 0.315; Loss 0.273; Loss 0.361; Loss 0.320; Loss 0.366; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.355; Loss 0.317; Loss 0.368; Loss 0.275; Loss 0.316; Loss 0.272; Loss 0.361; Loss 0.320; Loss 0.366; Loss 0.275; Loss 0.318; Loss 0.270; Loss 0.355; Loss 0.317; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.357; Loss 0.318; Loss 0.369; Loss 0.275; Loss 0.317; Loss 0.271; Loss 0.358; Loss 0.317; Loss 0.368; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.3042, -0.3852, -0.1261,  0.1511, -0.4862,  0.2188,  0.5213,  0.4802,  0.3901,  0.1760,  0.1758,  0.0924], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff = train_model(2000, lr=0.3)\n",
    "coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25c76b",
   "metadata": {
    "papermill": {
     "duration": 0.142015,
     "end_time": "2022-11-16T07:30:23.495180",
     "exception": false,
     "start_time": "2022-11-16T07:30:23.353165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It does!\n",
    "\n",
    "Let's take a look at the coefficients for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "100ff8a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:23.776431Z",
     "iopub.status.busy": "2022-11-16T07:30:23.775642Z",
     "iopub.status.idle": "2022-11-16T07:30:23.784594Z",
     "shell.execute_reply": "2022-11-16T07:30:23.783437Z"
    },
    "papermill": {
     "duration": 0.152658,
     "end_time": "2022-11-16T07:30:23.786823",
     "exception": false,
     "start_time": "2022-11-16T07:30:23.634165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.3042),\n",
       " 'SibSp': tensor(-0.3852),\n",
       " 'Parch': tensor(-0.1261),\n",
       " 'LogFare': tensor(0.1511),\n",
       " 'Sex_male': tensor(-0.4862),\n",
       " 'Sex_female': tensor(0.2188),\n",
       " 'Pclass_1': tensor(0.5213),\n",
       " 'Pclass_2': tensor(0.4802),\n",
       " 'Pclass_3': tensor(0.3901),\n",
       " 'Embarked_C': tensor(0.1760),\n",
       " 'Embarked_Q': tensor(0.1758),\n",
       " 'Embarked_S': tensor(0.0924)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_coeffs(coeffs): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n",
    "show_coeffs(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "191979a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:24.066912Z",
     "iopub.status.busy": "2022-11-16T07:30:24.066649Z",
     "iopub.status.idle": "2022-11-16T07:30:24.076926Z",
     "shell.execute_reply": "2022-11-16T07:30:24.075924Z"
    },
    "papermill": {
     "duration": 0.152079,
     "end_time": "2022-11-16T07:30:24.079407",
     "exception": false,
     "start_time": "2022-11-16T07:30:23.927328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8463,  0.0409,  0.0396,  0.1223,  0.0552, -0.0162,  0.8133,  0.7488, -0.1966,  0.7008, -0.0724, -0.0131, -0.0277,  0.7463,\n",
       "        -0.0842,  0.0366, -0.0394,  0.7551,  0.0178,  0.6384, -0.0421, -0.0052,  0.8128,  0.6201, -0.0293,  0.0183,  0.6888, -0.0280,\n",
       "        -0.0134,  0.7460,  0.7448,  0.4514, -0.0231, -0.0664,  0.8235,  0.5432,  0.0348,  0.9278, -0.0416,  0.6111,  0.0732, -0.0416,\n",
       "        -0.0147,  0.8997, -0.0264,  0.5300, -0.0045, -0.0896,  0.0386,  0.6688,  0.0564, -0.2270, -0.1884, -0.0483,  0.0466,  0.0238,\n",
       "         0.0409, -0.1208, -0.0302, -0.0434,  0.1783, -0.0660, -0.0936, -0.0306,  0.6557,  0.1321,  0.0590, -0.0739, -0.0737,  0.6850,\n",
       "        -0.0497,  0.7191,  0.0276, -0.0381,  0.1159, -0.0120, -0.0416,  0.0440,  0.0780, -0.0252,  0.0545,  0.8328, -0.0383, -0.0439,\n",
       "         0.6604,  0.0755,  0.2082,  0.8052,  0.7983,  0.0628, -0.0712, -0.0416,  0.9152,  0.0168,  0.7376,  0.0967, -0.0088,  0.6744,\n",
       "         0.7536,  0.0570, -0.0885,  0.7460, -0.0725, -0.0649,  0.0597, -0.0095, -0.0609,  0.6594,  0.1773, -0.1117,  0.7037,  0.6066,\n",
       "         0.1193,  0.8515, -0.0416,  0.7447,  0.4939,  0.0409, -0.1112,  0.8385, -0.1884,  0.0199,  0.0409,  0.5319,  0.0396,  0.1003,\n",
       "         0.6589,  0.6553, -0.0076, -0.0493,  0.8799, -0.0744,  0.6862,  0.7317,  0.8976, -0.0226, -0.0732, -0.0571,  0.0814,  0.7331,\n",
       "         0.0362,  0.7761, -0.1246,  0.0105,  0.5239,  0.6506, -0.0933,  0.7279,  0.8402,  0.6591,  0.6079,  0.7039,  0.7707, -0.0819,\n",
       "        -0.0307, -0.4191, -0.0416,  0.6348,  0.0210, -0.0286,  0.9198,  0.0928, -0.0695,  0.0165,  0.8271,  0.7777,  0.7103,  0.6956,\n",
       "        -0.1132,  0.0018,  0.5887, -0.0096,  0.8027, -0.0381, -0.1180,  0.7571,  0.1197, -0.0387])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(coeff*val_indep).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dfca42",
   "metadata": {
    "papermill": {
     "duration": 0.139383,
     "end_time": "2022-11-16T07:30:24.358592",
     "exception": false,
     "start_time": "2022-11-16T07:30:24.219209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Measuring accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b802b",
   "metadata": {
    "papermill": {
     "duration": 0.139869,
     "end_time": "2022-11-16T07:30:24.639072",
     "exception": false,
     "start_time": "2022-11-16T07:30:24.499203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The Kaggle competition is not, however, scored by absolute error (which is our loss function). It's scored by *accuracy* -- the proportion of rows where we correctly predict survival. Let's see how accurate we were on the validation set. First, calculate the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cceff518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:24.978609Z",
     "iopub.status.busy": "2022-11-16T07:30:24.978131Z",
     "iopub.status.idle": "2022-11-16T07:30:24.982947Z",
     "shell.execute_reply": "2022-11-16T07:30:24.982346Z"
    },
    "papermill": {
     "duration": 0.149962,
     "end_time": "2022-11-16T07:30:24.984991",
     "exception": false,
     "start_time": "2022-11-16T07:30:24.835029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = calc_preds(coeff, val_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0f28cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:25.271707Z",
     "iopub.status.busy": "2022-11-16T07:30:25.271403Z",
     "iopub.status.idle": "2022-11-16T07:30:25.278282Z",
     "shell.execute_reply": "2022-11-16T07:30:25.277552Z"
    },
    "papermill": {
     "duration": 0.153442,
     "end_time": "2022-11-16T07:30:25.280125",
     "exception": false,
     "start_time": "2022-11-16T07:30:25.126683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8463,  0.0409,  0.0396,  0.1223,  0.0552, -0.0162,  0.8133,  0.7488, -0.1966,  0.7008, -0.0724, -0.0131, -0.0277,  0.7463,\n",
       "        -0.0842,  0.0366, -0.0394,  0.7551,  0.0178,  0.6384, -0.0421, -0.0052,  0.8128,  0.6201, -0.0293,  0.0183,  0.6888, -0.0280,\n",
       "        -0.0134,  0.7460,  0.7448,  0.4514, -0.0231, -0.0664,  0.8235,  0.5432,  0.0348,  0.9278, -0.0416,  0.6111,  0.0732, -0.0416,\n",
       "        -0.0147,  0.8997, -0.0264,  0.5300, -0.0045, -0.0896,  0.0386,  0.6688,  0.0564, -0.2270, -0.1884, -0.0483,  0.0466,  0.0238,\n",
       "         0.0409, -0.1208, -0.0302, -0.0434,  0.1783, -0.0660, -0.0936, -0.0306,  0.6557,  0.1321,  0.0590, -0.0739, -0.0737,  0.6850,\n",
       "        -0.0497,  0.7191,  0.0276, -0.0381,  0.1159, -0.0120, -0.0416,  0.0440,  0.0780, -0.0252,  0.0545,  0.8328, -0.0383, -0.0439,\n",
       "         0.6604,  0.0755,  0.2082,  0.8052,  0.7983,  0.0628, -0.0712, -0.0416,  0.9152,  0.0168,  0.7376,  0.0967, -0.0088,  0.6744,\n",
       "         0.7536,  0.0570, -0.0885,  0.7460, -0.0725, -0.0649,  0.0597, -0.0095, -0.0609,  0.6594,  0.1773, -0.1117,  0.7037,  0.6066,\n",
       "         0.1193,  0.8515, -0.0416,  0.7447,  0.4939,  0.0409, -0.1112,  0.8385, -0.1884,  0.0199,  0.0409,  0.5319,  0.0396,  0.1003,\n",
       "         0.6589,  0.6553, -0.0076, -0.0493,  0.8799, -0.0744,  0.6862,  0.7317,  0.8976, -0.0226, -0.0732, -0.0571,  0.0814,  0.7331,\n",
       "         0.0362,  0.7761, -0.1246,  0.0105,  0.5239,  0.6506, -0.0933,  0.7279,  0.8402,  0.6591,  0.6079,  0.7039,  0.7707, -0.0819,\n",
       "        -0.0307, -0.4191, -0.0416,  0.6348,  0.0210, -0.0286,  0.9198,  0.0928, -0.0695,  0.0165,  0.8271,  0.7777,  0.7103,  0.6956,\n",
       "        -0.1132,  0.0018,  0.5887, -0.0096,  0.8027, -0.0381, -0.1180,  0.7571,  0.1197, -0.0387])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86dc0b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:25.566057Z",
     "iopub.status.busy": "2022-11-16T07:30:25.565779Z",
     "iopub.status.idle": "2022-11-16T07:30:25.573148Z",
     "shell.execute_reply": "2022-11-16T07:30:25.572299Z"
    },
    "papermill": {
     "duration": 0.153469,
     "end_time": "2022-11-16T07:30:25.575016",
     "exception": false,
     "start_time": "2022-11-16T07:30:25.421547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0912, -0.0000, -0.0000,  0.0627, -0.0000,  0.2188,  0.0000,  0.4802,  0.0000,  0.0000,  0.1758,  0.0000],\n",
       "        [-0.0912, -0.0000, -0.0000,  0.0525, -0.4862,  0.0000,  0.0000,  0.0000,  0.3901,  0.0000,  0.1758,  0.0000],\n",
       "        [-0.0912, -0.0000, -0.0000,  0.0510, -0.4862,  0.0000,  0.0000,  0.0000,  0.3901,  0.1760,  0.0000,  0.0000],\n",
       "        [-0.0684, -0.0000, -0.0000,  0.1044, -0.4862,  0.0000,  0.0000,  0.4802,  0.0000,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.0951, -0.0000, -0.0000,  0.0639, -0.4862,  0.0000,  0.0000,  0.4802,  0.0000,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.1293, -0.0481, -0.0000,  0.0748, -0.4862,  0.0000,  0.0000,  0.4802,  0.0000,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.0152, -0.0000, -0.0210,  0.0646, -0.0000,  0.2188,  0.0000,  0.0000,  0.3901,  0.1760,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-0.0722, -0.0000, -0.0000,  0.0664, -0.4862,  0.0000,  0.0000,  0.0000,  0.3901,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.0836, -0.0481, -0.0000,  0.1020, -0.0000,  0.2188,  0.5213,  0.0000,  0.0000,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.0912, -0.0000, -0.0000,  0.0569, -0.4862,  0.0000,  0.0000,  0.0000,  0.3901,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.1673, -0.0000, -0.0000,  0.0530, -0.4862,  0.0000,  0.0000,  0.0000,  0.3901,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.1369, -0.0000, -0.0420,  0.1035, -0.0000,  0.2188,  0.5213,  0.0000,  0.0000,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.0912, -0.0000, -0.0000,  0.0835, -0.4862,  0.0000,  0.5213,  0.0000,  0.0000,  0.0000,  0.0000,  0.0924],\n",
       "        [-0.0342, -0.0481, -0.0210,  0.0684, -0.4862,  0.0000,  0.0000,  0.0000,  0.3901,  0.0000,  0.0000,  0.0924]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff*val_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e5b9695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:25.862723Z",
     "iopub.status.busy": "2022-11-16T07:30:25.862434Z",
     "iopub.status.idle": "2022-11-16T07:30:25.867906Z",
     "shell.execute_reply": "2022-11-16T07:30:25.866842Z"
    },
    "papermill": {
     "duration": 0.154206,
     "end_time": "2022-11-16T07:30:25.870154",
     "exception": false,
     "start_time": "2022-11-16T07:30:25.715948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(coeff*val_indep).sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fcdf132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:26.158200Z",
     "iopub.status.busy": "2022-11-16T07:30:26.157958Z",
     "iopub.status.idle": "2022-11-16T07:30:26.164733Z",
     "shell.execute_reply": "2022-11-16T07:30:26.163807Z"
    },
    "papermill": {
     "duration": 0.153782,
     "end_time": "2022-11-16T07:30:26.166346",
     "exception": false,
     "start_time": "2022-11-16T07:30:26.012564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False, False, False, False,  True,  True, False,  True, False, False, False,  True, False, False, False,  True, False,\n",
       "         True, False, False,  True,  True, False, False,  True, False, False,  True,  True, False, False, False,  True,  True, False,  True,\n",
       "        False,  True, False, False, False,  True, False,  True, False, False, False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True, False, False, False, False,  True, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False,  True, False, False,  True, False, False,  True,  True, False, False, False,  True, False,  True,\n",
       "        False, False,  True,  True, False, False,  True, False, False, False, False, False,  True, False, False,  True,  True, False,  True,\n",
       "        False,  True, False, False, False,  True, False, False, False,  True, False, False,  True,  True, False, False,  True, False,  True,\n",
       "         True,  True, False, False, False, False,  True, False,  True, False, False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True, False, False, False, False,  True, False, False,  True, False, False, False,  True,  True,  True,  True, False, False,  True,\n",
       "        False,  True, False, False,  True, False, False])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = preds>0.5\n",
    "check.shape\n",
    "preds>0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820d58a",
   "metadata": {
    "papermill": {
     "duration": 0.142252,
     "end_time": "2022-11-16T07:30:26.449380",
     "exception": false,
     "start_time": "2022-11-16T07:30:26.307128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll assume that any passenger with a score of over `0.5` is predicted to survive. So that means we're correct for each row where `preds>0.5` is the same as the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bc6bf49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:26.737794Z",
     "iopub.status.busy": "2022-11-16T07:30:26.737549Z",
     "iopub.status.idle": "2022-11-16T07:30:26.742167Z",
     "shell.execute_reply": "2022-11-16T07:30:26.741707Z"
    },
    "papermill": {
     "duration": 0.151418,
     "end_time": "2022-11-16T07:30:26.743928",
     "exception": false,
     "start_time": "2022-11-16T07:30:26.592510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = val_dep.bool()==(preds>0.5)\n",
    "results[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fd678",
   "metadata": {
    "papermill": {
     "duration": 0.1422,
     "end_time": "2022-11-16T07:30:27.029194",
     "exception": false,
     "start_time": "2022-11-16T07:30:26.886994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see what our average accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc50780e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:27.320635Z",
     "iopub.status.busy": "2022-11-16T07:30:27.320363Z",
     "iopub.status.idle": "2022-11-16T07:30:27.325146Z",
     "shell.execute_reply": "2022-11-16T07:30:27.324672Z"
    },
    "papermill": {
     "duration": 0.151712,
     "end_time": "2022-11-16T07:30:27.327254",
     "exception": false,
     "start_time": "2022-11-16T07:30:27.175542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8034)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98625e",
   "metadata": {
    "papermill": {
     "duration": 0.142021,
     "end_time": "2022-11-16T07:30:27.613413",
     "exception": false,
     "start_time": "2022-11-16T07:30:27.471392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That's not a bad start at all! We'll create a function so we can calcuate the accuracy easy for other models we train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c2e38bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:27.898636Z",
     "iopub.status.busy": "2022-11-16T07:30:27.898191Z",
     "iopub.status.idle": "2022-11-16T07:30:27.903806Z",
     "shell.execute_reply": "2022-11-16T07:30:27.903361Z"
    },
    "papermill": {
     "duration": 0.151597,
     "end_time": "2022-11-16T07:30:27.905615",
     "exception": false,
     "start_time": "2022-11-16T07:30:27.754018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8034)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(coeff): return (val_dep.bool()==(calc_preds(coeff, val_indep)>0.5)).float().mean()\n",
    "acc(coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32477fc6",
   "metadata": {
    "papermill": {
     "duration": 0.145378,
     "end_time": "2022-11-16T07:30:28.196278",
     "exception": false,
     "start_time": "2022-11-16T07:30:28.050900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37310a25",
   "metadata": {
    "papermill": {
     "duration": 0.1438,
     "end_time": "2022-11-16T07:30:28.505367",
     "exception": false,
     "start_time": "2022-11-16T07:30:28.361567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Looking at our predictions, there's one obvious problem -- some of our predictions of the probability of survival are `>1`, and some are `<0`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d8145",
   "metadata": {
    "papermill": {
     "duration": 0.143768,
     "end_time": "2022-11-16T07:30:28.792921",
     "exception": false,
     "start_time": "2022-11-16T07:30:28.649153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To fix this, we should pass every prediction through the *sigmoid function*, which has a minimum at zero and maximum at one, and is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0525c101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:29.083843Z",
     "iopub.status.busy": "2022-11-16T07:30:29.083240Z",
     "iopub.status.idle": "2022-11-16T07:30:30.126771Z",
     "shell.execute_reply": "2022-11-16T07:30:30.126244Z"
    },
    "papermill": {
     "duration": 1.188556,
     "end_time": "2022-11-16T07:30:30.128691",
     "exception": false,
     "start_time": "2022-11-16T07:30:28.940135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy\n",
    "sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e402464",
   "metadata": {
    "papermill": {
     "duration": 0.143445,
     "end_time": "2022-11-16T07:30:30.419842",
     "exception": false,
     "start_time": "2022-11-16T07:30:30.276397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "PyTorch already defines that function for us, so we can modify `calc_preds` to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49428ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:30.709901Z",
     "iopub.status.busy": "2022-11-16T07:30:30.709589Z",
     "iopub.status.idle": "2022-11-16T07:30:30.715063Z",
     "shell.execute_reply": "2022-11-16T07:30:30.713892Z"
    },
    "papermill": {
     "duration": 0.15347,
     "end_time": "2022-11-16T07:30:30.716900",
     "exception": false,
     "start_time": "2022-11-16T07:30:30.563430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b803b1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:31.008168Z",
     "iopub.status.busy": "2022-11-16T07:30:31.007914Z",
     "iopub.status.idle": "2022-11-16T07:30:31.015136Z",
     "shell.execute_reply": "2022-11-16T07:30:31.014652Z"
    },
    "papermill": {
     "duration": 0.154676,
     "end_time": "2022-11-16T07:30:31.017250",
     "exception": false,
     "start_time": "2022-11-16T07:30:30.862574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6998, 0.5102, 0.5099, 0.5305, 0.5138, 0.4959, 0.6928, 0.6789, 0.4510, 0.6684, 0.4819, 0.4967, 0.4931, 0.6784, 0.4790, 0.5092,\n",
       "        0.4901, 0.6803, 0.5045, 0.6544, 0.4895, 0.4987, 0.6927, 0.6502, 0.4927, 0.5046, 0.6657, 0.4930, 0.4966, 0.6783, 0.6780, 0.6110,\n",
       "        0.4942, 0.4834, 0.6950, 0.6326, 0.5087, 0.7166, 0.4896, 0.6482, 0.5183, 0.4896, 0.4963, 0.7109, 0.4934, 0.6295, 0.4989, 0.4776,\n",
       "        0.5097, 0.6612, 0.5141, 0.4435, 0.4530, 0.4879, 0.5117, 0.5059, 0.5102, 0.4698, 0.4924, 0.4892, 0.5445, 0.4835, 0.4766, 0.4924,\n",
       "        0.6583, 0.5330, 0.5147, 0.4815, 0.4816, 0.6649, 0.4876, 0.6724, 0.5069, 0.4905, 0.5289, 0.4970, 0.4896, 0.5110, 0.5195, 0.4937,\n",
       "        0.5136, 0.6970, 0.4904, 0.4890, 0.6594, 0.5189, 0.5519, 0.6911, 0.6896, 0.5157, 0.4822, 0.4896, 0.7141, 0.5042, 0.6765, 0.5242,\n",
       "        0.4978, 0.6625, 0.6800, 0.5142, 0.4779, 0.6783, 0.4819, 0.4838, 0.5149, 0.4976, 0.4848, 0.6591, 0.5442, 0.4721, 0.6690, 0.6472,\n",
       "        0.5298, 0.7009, 0.4896, 0.6780, 0.6210, 0.5102, 0.4722, 0.6981, 0.4530, 0.5050, 0.5102, 0.6299, 0.5099, 0.5251, 0.6590, 0.6582,\n",
       "        0.4981, 0.4877, 0.7068, 0.4814, 0.6651, 0.6752, 0.7105, 0.4943, 0.4817, 0.4857, 0.5203, 0.6755, 0.5090, 0.6848, 0.4689, 0.5026,\n",
       "        0.6281, 0.6571, 0.4767, 0.6743, 0.6985, 0.6591, 0.6475, 0.6691, 0.6837, 0.4795, 0.4923, 0.3967, 0.4896, 0.6536, 0.5052, 0.4928,\n",
       "        0.7150, 0.5232, 0.4826, 0.5041, 0.6957, 0.6852, 0.6705, 0.6672, 0.4717, 0.5005, 0.6431, 0.4976, 0.6906, 0.4905, 0.4705, 0.6807,\n",
       "        0.5299, 0.4903])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_preds(coeff,val_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7446a21e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:31.310908Z",
     "iopub.status.busy": "2022-11-16T07:30:31.310328Z",
     "iopub.status.idle": "2022-11-16T07:30:31.317677Z",
     "shell.execute_reply": "2022-11-16T07:30:31.316362Z"
    },
    "papermill": {
     "duration": 0.158388,
     "end_time": "2022-11-16T07:30:31.319953",
     "exception": false,
     "start_time": "2022-11-16T07:30:31.161565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8463,  0.0409,  0.0396,  0.1223,  0.0552, -0.0162,  0.8133,  0.7488, -0.1966,  0.7008, -0.0724, -0.0131, -0.0277,  0.7463,\n",
       "        -0.0842,  0.0366, -0.0394,  0.7551,  0.0178,  0.6384, -0.0421, -0.0052,  0.8128,  0.6201, -0.0293,  0.0183,  0.6888, -0.0280,\n",
       "        -0.0134,  0.7460,  0.7448,  0.4514, -0.0231, -0.0664,  0.8235,  0.5432,  0.0348,  0.9278, -0.0416,  0.6111,  0.0732, -0.0416,\n",
       "        -0.0147,  0.8997, -0.0264,  0.5300, -0.0045, -0.0896,  0.0386,  0.6688,  0.0564, -0.2270, -0.1884, -0.0483,  0.0466,  0.0238,\n",
       "         0.0409, -0.1208, -0.0302, -0.0434,  0.1783, -0.0660, -0.0936, -0.0306,  0.6557,  0.1321,  0.0590, -0.0739, -0.0737,  0.6850,\n",
       "        -0.0497,  0.7191,  0.0276, -0.0381,  0.1159, -0.0120, -0.0416,  0.0440,  0.0780, -0.0252,  0.0545,  0.8328, -0.0383, -0.0439,\n",
       "         0.6604,  0.0755,  0.2082,  0.8052,  0.7983,  0.0628, -0.0712, -0.0416,  0.9152,  0.0168,  0.7376,  0.0967, -0.0088,  0.6744,\n",
       "         0.7536,  0.0570, -0.0885,  0.7460, -0.0725, -0.0649,  0.0597, -0.0095, -0.0609,  0.6594,  0.1773, -0.1117,  0.7037,  0.6066,\n",
       "         0.1193,  0.8515, -0.0416,  0.7447,  0.4939,  0.0409, -0.1112,  0.8385, -0.1884,  0.0199,  0.0409,  0.5319,  0.0396,  0.1003,\n",
       "         0.6589,  0.6553, -0.0076, -0.0493,  0.8799, -0.0744,  0.6862,  0.7317,  0.8976, -0.0226, -0.0732, -0.0571,  0.0814,  0.7331,\n",
       "         0.0362,  0.7761, -0.1246,  0.0105,  0.5239,  0.6506, -0.0933,  0.7279,  0.8402,  0.6591,  0.6079,  0.7039,  0.7707, -0.0819,\n",
       "        -0.0307, -0.4191, -0.0416,  0.6348,  0.0210, -0.0286,  0.9198,  0.0928, -0.0695,  0.0165,  0.8271,  0.7777,  0.7103,  0.6956,\n",
       "        -0.1132,  0.0018,  0.5887, -0.0096,  0.8027, -0.0381, -0.1180,  0.7571,  0.1197, -0.0387])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_indep*coeff).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03b171df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:31.615451Z",
     "iopub.status.busy": "2022-11-16T07:30:31.614669Z",
     "iopub.status.idle": "2022-11-16T07:30:31.622144Z",
     "shell.execute_reply": "2022-11-16T07:30:31.620983Z"
    },
    "papermill": {
     "duration": 0.15855,
     "end_time": "2022-11-16T07:30:31.624139",
     "exception": false,
     "start_time": "2022-11-16T07:30:31.465589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8463,  0.0409,  0.0396,  0.1223,  0.0552, -0.0162,  0.8133,  0.7488, -0.1966,  0.7008, -0.0724, -0.0131, -0.0277,  0.7463,\n",
       "        -0.0842,  0.0366, -0.0394,  0.7551,  0.0178,  0.6384, -0.0421, -0.0052,  0.8128,  0.6201, -0.0293,  0.0183,  0.6888, -0.0280,\n",
       "        -0.0134,  0.7460,  0.7448,  0.4514, -0.0231, -0.0664,  0.8235,  0.5432,  0.0348,  0.9278, -0.0416,  0.6111,  0.0732, -0.0416,\n",
       "        -0.0147,  0.8997, -0.0264,  0.5300, -0.0045, -0.0896,  0.0386,  0.6688,  0.0564, -0.2270, -0.1884, -0.0483,  0.0466,  0.0238,\n",
       "         0.0409, -0.1208, -0.0302, -0.0434,  0.1783, -0.0660, -0.0936, -0.0306,  0.6557,  0.1321,  0.0590, -0.0739, -0.0737,  0.6850,\n",
       "        -0.0497,  0.7191,  0.0276, -0.0381,  0.1159, -0.0120, -0.0416,  0.0440,  0.0780, -0.0252,  0.0545,  0.8328, -0.0383, -0.0439,\n",
       "         0.6604,  0.0755,  0.2082,  0.8052,  0.7983,  0.0628, -0.0712, -0.0416,  0.9152,  0.0168,  0.7376,  0.0967, -0.0088,  0.6744,\n",
       "         0.7536,  0.0570, -0.0885,  0.7460, -0.0725, -0.0649,  0.0597, -0.0095, -0.0609,  0.6594,  0.1773, -0.1117,  0.7037,  0.6066,\n",
       "         0.1193,  0.8515, -0.0416,  0.7447,  0.4939,  0.0409, -0.1112,  0.8385, -0.1884,  0.0199,  0.0409,  0.5319,  0.0396,  0.1003,\n",
       "         0.6589,  0.6553, -0.0076, -0.0493,  0.8799, -0.0744,  0.6862,  0.7317,  0.8976, -0.0226, -0.0732, -0.0571,  0.0814,  0.7331,\n",
       "         0.0362,  0.7761, -0.1246,  0.0105,  0.5239,  0.6506, -0.0933,  0.7279,  0.8402,  0.6591,  0.6079,  0.7039,  0.7707, -0.0819,\n",
       "        -0.0307, -0.4191, -0.0416,  0.6348,  0.0210, -0.0286,  0.9198,  0.0928, -0.0695,  0.0165,  0.8271,  0.7777,  0.7103,  0.6956,\n",
       "        -0.1132,  0.0018,  0.5887, -0.0096,  0.8027, -0.0381, -0.1180,  0.7571,  0.1197, -0.0387])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00041c39",
   "metadata": {
    "papermill": {
     "duration": 0.146026,
     "end_time": "2022-11-16T07:30:31.916338",
     "exception": false,
     "start_time": "2022-11-16T07:30:31.770312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's train a new model now, using this updated function to calculate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d7baff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:32.214399Z",
     "iopub.status.busy": "2022-11-16T07:30:32.213613Z",
     "iopub.status.idle": "2022-11-16T07:30:32.232369Z",
     "shell.execute_reply": "2022-11-16T07:30:32.231258Z"
    },
    "papermill": {
     "duration": 0.17149,
     "end_time": "2022-11-16T07:30:32.234450",
     "exception": false,
     "start_time": "2022-11-16T07:30:32.062960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.510; Loss 0.327; Loss 0.294; Loss 0.207; Loss 0.201; Loss 0.199; Loss 0.198; Loss 0.197; Loss 0.196; Loss 0.196; Loss 0.196; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c6fae",
   "metadata": {
    "papermill": {
     "duration": 0.146626,
     "end_time": "2022-11-16T07:30:32.527344",
     "exception": false,
     "start_time": "2022-11-16T07:30:32.380718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The loss has improved by a lot. Let's check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f967dca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:32.819982Z",
     "iopub.status.busy": "2022-11-16T07:30:32.819729Z",
     "iopub.status.idle": "2022-11-16T07:30:32.825709Z",
     "shell.execute_reply": "2022-11-16T07:30:32.825045Z"
    },
    "papermill": {
     "duration": 0.155269,
     "end_time": "2022-11-16T07:30:32.827476",
     "exception": false,
     "start_time": "2022-11-16T07:30:32.672207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -1.5061,  -1.1575,  -0.4267,   0.2543, -10.3320,   8.4185,   3.8389,   2.1398,  -6.2331,   1.4771,   2.1168,  -4.7958],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f694a831",
   "metadata": {
    "papermill": {
     "duration": 0.146816,
     "end_time": "2022-11-16T07:30:33.121167",
     "exception": false,
     "start_time": "2022-11-16T07:30:32.974351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That's improved too! Here's the coefficients of our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6998a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:33.420105Z",
     "iopub.status.busy": "2022-11-16T07:30:33.419792Z",
     "iopub.status.idle": "2022-11-16T07:30:33.430243Z",
     "shell.execute_reply": "2022-11-16T07:30:33.429372Z"
    },
    "papermill": {
     "duration": 0.162441,
     "end_time": "2022-11-16T07:30:33.432670",
     "exception": false,
     "start_time": "2022-11-16T07:30:33.270229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.3042),\n",
       " 'SibSp': tensor(-0.3852),\n",
       " 'Parch': tensor(-0.1261),\n",
       " 'LogFare': tensor(0.1511),\n",
       " 'Sex_male': tensor(-0.4862),\n",
       " 'Sex_female': tensor(0.2188),\n",
       " 'Pclass_1': tensor(0.5213),\n",
       " 'Pclass_2': tensor(0.4802),\n",
       " 'Pclass_3': tensor(0.3901),\n",
       " 'Embarked_C': tensor(0.1760),\n",
       " 'Embarked_Q': tensor(0.1758),\n",
       " 'Embarked_S': tensor(0.0924)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs(coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003a2b9",
   "metadata": {
    "papermill": {
     "duration": 0.149593,
     "end_time": "2022-11-16T07:30:33.729698",
     "exception": false,
     "start_time": "2022-11-16T07:30:33.580105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These coefficients seem reasonable -- in general, older people and males were less likely to survive, and first class passengers were more likely to survive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e8428",
   "metadata": {
    "papermill": {
     "duration": 0.146124,
     "end_time": "2022-11-16T07:30:34.023814",
     "exception": false,
     "start_time": "2022-11-16T07:30:33.877690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9328c305",
   "metadata": {
    "papermill": {
     "duration": 0.147535,
     "end_time": "2022-11-16T07:30:34.318976",
     "exception": false,
     "start_time": "2022-11-16T07:30:34.171441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we've got a trained model, we can prepare a submission to Kaggle. To do that, first we need to read the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db1e21e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:34.614618Z",
     "iopub.status.busy": "2022-11-16T07:30:34.614354Z",
     "iopub.status.idle": "2022-11-16T07:30:34.627862Z",
     "shell.execute_reply": "2022-11-16T07:30:34.626639Z"
    },
    "papermill": {
     "duration": 0.164039,
     "end_time": "2022-11-16T07:30:34.629854",
     "exception": false,
     "start_time": "2022-11-16T07:30:34.465815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9cc01",
   "metadata": {
    "papermill": {
     "duration": 0.148691,
     "end_time": "2022-11-16T07:30:34.923749",
     "exception": false,
     "start_time": "2022-11-16T07:30:34.775058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this case, it turns out that the test set is missing `Fare` for one passenger. We'll just fill it with `0` to avoid problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab876579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:35.214800Z",
     "iopub.status.busy": "2022-11-16T07:30:35.214500Z",
     "iopub.status.idle": "2022-11-16T07:30:35.219619Z",
     "shell.execute_reply": "2022-11-16T07:30:35.218491Z"
    },
    "papermill": {
     "duration": 0.153951,
     "end_time": "2022-11-16T07:30:35.221546",
     "exception": false,
     "start_time": "2022-11-16T07:30:35.067595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst_df['Fare'] = tst_df.Fare.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026bb8c",
   "metadata": {
    "papermill": {
     "duration": 0.14519,
     "end_time": "2022-11-16T07:30:35.511980",
     "exception": false,
     "start_time": "2022-11-16T07:30:35.366790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can just copy the same steps we did to our training set and do the same exact things on our test set to preprocess the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49620da8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:35.804720Z",
     "iopub.status.busy": "2022-11-16T07:30:35.804321Z",
     "iopub.status.idle": "2022-11-16T07:30:35.823018Z",
     "shell.execute_reply": "2022-11-16T07:30:35.821836Z"
    },
    "papermill": {
     "duration": 0.168782,
     "end_time": "2022-11-16T07:30:35.825427",
     "exception": false,
     "start_time": "2022-11-16T07:30:35.656645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst_df.fillna(modes, inplace=True)\n",
    "tst_df['LogFare'] = np.log(tst_df['Fare']+1)\n",
    "tst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "\n",
    "tst_indep = tensor(tst_df[indep_cols].values, dtype=torch.float)\n",
    "tst_indep = tst_indep / vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3a23a",
   "metadata": {
    "papermill": {
     "duration": 0.147672,
     "end_time": "2022-11-16T07:30:36.120887",
     "exception": false,
     "start_time": "2022-11-16T07:30:35.973215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's calculate our predictions of which passengers survived in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c830ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:36.412580Z",
     "iopub.status.busy": "2022-11-16T07:30:36.412119Z",
     "iopub.status.idle": "2022-11-16T07:30:36.416209Z",
     "shell.execute_reply": "2022-11-16T07:30:36.415757Z"
    },
    "papermill": {
     "duration": 0.150835,
     "end_time": "2022-11-16T07:30:36.417913",
     "exception": false,
     "start_time": "2022-11-16T07:30:36.267078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst_df['Survived'] = (calc_preds(tst_indep, coeffs)>0.5).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396e1c7",
   "metadata": {
    "papermill": {
     "duration": 0.14744,
     "end_time": "2022-11-16T07:30:36.710103",
     "exception": false,
     "start_time": "2022-11-16T07:30:36.562663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The sample submission on the Kaggle competition site shows that we're expected to upload a CSV with just `PassengerId` and `Survived`, so let's create that and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3404c17b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:37.003034Z",
     "iopub.status.busy": "2022-11-16T07:30:37.002770Z",
     "iopub.status.idle": "2022-11-16T07:30:37.013452Z",
     "shell.execute_reply": "2022-11-16T07:30:37.012845Z"
    },
    "papermill": {
     "duration": 0.160624,
     "end_time": "2022-11-16T07:30:37.015364",
     "exception": false,
     "start_time": "2022-11-16T07:30:36.854740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = tst_df[['PassengerId','Survived']]\n",
    "sub_df.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9585ee",
   "metadata": {
    "papermill": {
     "duration": 0.143101,
     "end_time": "2022-11-16T07:30:37.303270",
     "exception": false,
     "start_time": "2022-11-16T07:30:37.160169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can check the first few rows of the file to make sure it looks reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c96e8bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:37.594089Z",
     "iopub.status.busy": "2022-11-16T07:30:37.593617Z",
     "iopub.status.idle": "2022-11-16T07:30:37.860184Z",
     "shell.execute_reply": "2022-11-16T07:30:37.859204Z"
    },
    "papermill": {
     "duration": 0.416024,
     "end_time": "2022-11-16T07:30:37.862316",
     "exception": false,
     "start_time": "2022-11-16T07:30:37.446292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n"
     ]
    }
   ],
   "source": [
    "!head sub.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29831c5f",
   "metadata": {
    "papermill": {
     "duration": 0.146704,
     "end_time": "2022-11-16T07:30:38.154826",
     "exception": false,
     "start_time": "2022-11-16T07:30:38.008122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When you click \"save version\" in Kaggle, and wait for the notebook to run, you'll see that `sub.csv` appears in the \"Data\" tab. Clicking on that file will show a *Submit* button, which allows you to submit to the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13590e87",
   "metadata": {
    "papermill": {
     "duration": 0.14606,
     "end_time": "2022-11-16T07:30:38.451316",
     "exception": false,
     "start_time": "2022-11-16T07:30:38.305256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59105f76",
   "metadata": {
    "papermill": {
     "duration": 0.147272,
     "end_time": "2022-11-16T07:30:38.748385",
     "exception": false,
     "start_time": "2022-11-16T07:30:38.601113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can make things quite a bit neater...\n",
    "\n",
    "Take a look at the inner-most calculation we're doing to get the predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be98ea6f",
   "metadata": {
    "papermill": {
     "duration": 0.147243,
     "end_time": "2022-11-16T07:30:39.043165",
     "exception": false,
     "start_time": "2022-11-16T07:30:38.895922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we have a to test matrix product and rewrite the calc_preds fn using this. Then we have to make a 2-layer NN and then a n-layer deep learning neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6cc5bb44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:39.357770Z",
     "iopub.status.busy": "2022-11-16T07:30:39.357433Z",
     "iopub.status.idle": "2022-11-16T07:30:39.361707Z",
     "shell.execute_reply": "2022-11-16T07:30:39.360465Z"
    },
    "papermill": {
     "duration": 0.173209,
     "end_time": "2022-11-16T07:30:39.363358",
     "exception": false,
     "start_time": "2022-11-16T07:30:39.190149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_preds(coeffs,indeps):\n",
    "    return torch.sigmoid(indeps@coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee0ac836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:39.655852Z",
     "iopub.status.busy": "2022-11-16T07:30:39.655576Z",
     "iopub.status.idle": "2022-11-16T07:30:39.660298Z",
     "shell.execute_reply": "2022-11-16T07:30:39.659462Z"
    },
    "papermill": {
     "duration": 0.152032,
     "end_time": "2022-11-16T07:30:39.661971",
     "exception": false,
     "start_time": "2022-11-16T07:30:39.509939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss(coeffs, indeps, deps):\n",
    "    return torch.abs(calc_preds(coeffs,indeps)-deps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ede800",
   "metadata": {
    "papermill": {
     "duration": 0.146567,
     "end_time": "2022-11-16T07:30:39.954497",
     "exception": false,
     "start_time": "2022-11-16T07:30:39.807930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd11506e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:40.246766Z",
     "iopub.status.busy": "2022-11-16T07:30:40.246479Z",
     "iopub.status.idle": "2022-11-16T07:30:40.253479Z",
     "shell.execute_reply": "2022-11-16T07:30:40.252897Z"
    },
    "papermill": {
     "duration": 0.155569,
     "end_time": "2022-11-16T07:30:40.255388",
     "exception": false,
     "start_time": "2022-11-16T07:30:40.099819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3512, -13.6469,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n",
       "          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n",
       "         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n",
       "         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n",
       "        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n",
       "        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n",
       "        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,\n",
       "        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n",
       "        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n",
       "        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n",
       "          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n",
       "        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n",
       "        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n",
       "        -12.1838,  -3.0873, -21.6070,   7.0744, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b15a96",
   "metadata": {
    "papermill": {
     "duration": 0.150403,
     "end_time": "2022-11-16T07:30:40.552156",
     "exception": false,
     "start_time": "2022-11-16T07:30:40.401753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Multiplying elements together and then adding across rows is identical to doing a matrix-vector product! Python uses the `@` operator to indicate matrix products, and is supported by PyTorch tensors. Therefore, we can replicate the above calculate more simply like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74d6be7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:40.844865Z",
     "iopub.status.busy": "2022-11-16T07:30:40.844619Z",
     "iopub.status.idle": "2022-11-16T07:30:40.854755Z",
     "shell.execute_reply": "2022-11-16T07:30:40.853668Z"
    },
    "papermill": {
     "duration": 0.158656,
     "end_time": "2022-11-16T07:30:40.856677",
     "exception": false,
     "start_time": "2022-11-16T07:30:40.698021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3511, -13.6468,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n",
       "          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n",
       "         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n",
       "         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n",
       "        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n",
       "        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n",
       "        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,\n",
       "        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n",
       "        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n",
       "        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n",
       "          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n",
       "        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n",
       "        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n",
       "        -12.1838,  -3.0873, -21.6070,   7.0745, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310], grad_fn=<MvBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indep@coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570c162",
   "metadata": {
    "papermill": {
     "duration": 0.145185,
     "end_time": "2022-11-16T07:30:41.150210",
     "exception": false,
     "start_time": "2022-11-16T07:30:41.005025",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It also turns out that this is much faster, because matrix products in PyTorch are very highly optimised.\n",
    "\n",
    "Let's use this to replace how `calc_preds` works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6c068fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:41.446624Z",
     "iopub.status.busy": "2022-11-16T07:30:41.446367Z",
     "iopub.status.idle": "2022-11-16T07:30:41.450502Z",
     "shell.execute_reply": "2022-11-16T07:30:41.449470Z"
    },
    "papermill": {
     "duration": 0.153985,
     "end_time": "2022-11-16T07:30:41.452275",
     "exception": false,
     "start_time": "2022-11-16T07:30:41.298290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs) #used @ matrix multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0a529",
   "metadata": {
    "papermill": {
     "duration": 0.144714,
     "end_time": "2022-11-16T07:30:41.742711",
     "exception": false,
     "start_time": "2022-11-16T07:30:41.597997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In order to do matrix-matrix products (which we'll need in the next section), we need to turn `coeffs` into a column vector (i.e. a matrix with a single column), which we can do by passing a second argument `1` to `torch.rand()`, indicating that we want our coefficients to have one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62063157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:42.039586Z",
     "iopub.status.busy": "2022-11-16T07:30:42.039288Z",
     "iopub.status.idle": "2022-11-16T07:30:42.043812Z",
     "shell.execute_reply": "2022-11-16T07:30:42.042998Z"
    },
    "papermill": {
     "duration": 0.156137,
     "end_time": "2022-11-16T07:30:42.045539",
     "exception": false,
     "start_time": "2022-11-16T07:30:41.889402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff, 1)*0.1).requires_grad_() #made the vector a 2-rank tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ca915",
   "metadata": {
    "papermill": {
     "duration": 0.148364,
     "end_time": "2022-11-16T07:30:42.341303",
     "exception": false,
     "start_time": "2022-11-16T07:30:42.192939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll also need to turn our dependent variable into a column vector, which we can do by indexing the column dimension with the special value `None`, which tells PyTorch to add a new dimension in this position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "511037b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:42.640096Z",
     "iopub.status.busy": "2022-11-16T07:30:42.639836Z",
     "iopub.status.idle": "2022-11-16T07:30:42.644244Z",
     "shell.execute_reply": "2022-11-16T07:30:42.643423Z"
    },
    "papermill": {
     "duration": 0.154421,
     "end_time": "2022-11-16T07:30:42.645873",
     "exception": false,
     "start_time": "2022-11-16T07:30:42.491452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trn_dep = trn_dep[:,None] #these were tensors but only 1-rank, we made them 2-rank because everything needs to be same\n",
    "val_dep = val_dep[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056976b1",
   "metadata": {
    "papermill": {
     "duration": 0.146162,
     "end_time": "2022-11-16T07:30:42.939442",
     "exception": false,
     "start_time": "2022-11-16T07:30:42.793280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now train our model as before and confirm we get identical outputs...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e32be280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:43.234720Z",
     "iopub.status.busy": "2022-11-16T07:30:43.234426Z",
     "iopub.status.idle": "2022-11-16T07:30:43.251915Z",
     "shell.execute_reply": "2022-11-16T07:30:43.250978Z"
    },
    "papermill": {
     "duration": 0.167695,
     "end_time": "2022-11-16T07:30:43.253854",
     "exception": false,
     "start_time": "2022-11-16T07:30:43.086159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.512; Loss 0.323; Loss 0.290; Loss 0.205; Loss 0.200; Loss 0.198; Loss 0.197; Loss 0.197; Loss 0.196; Loss 0.196; Loss 0.196; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.195; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; Loss 0.194; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c679c",
   "metadata": {
    "papermill": {
     "duration": 0.147882,
     "end_time": "2022-11-16T07:30:43.551649",
     "exception": false,
     "start_time": "2022-11-16T07:30:43.403767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "...and identical accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bdef3b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:43.851964Z",
     "iopub.status.busy": "2022-11-16T07:30:43.851712Z",
     "iopub.status.idle": "2022-11-16T07:30:43.859114Z",
     "shell.execute_reply": "2022-11-16T07:30:43.858179Z"
    },
    "papermill": {
     "duration": 0.15988,
     "end_time": "2022-11-16T07:30:43.861065",
     "exception": false,
     "start_time": "2022-11-16T07:30:43.701185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda16259",
   "metadata": {
    "papermill": {
     "duration": 0.148704,
     "end_time": "2022-11-16T07:30:44.158693",
     "exception": false,
     "start_time": "2022-11-16T07:30:44.009989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## A neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c947e2e",
   "metadata": {
    "papermill": {
     "duration": 0.145887,
     "end_time": "2022-11-16T07:30:44.453262",
     "exception": false,
     "start_time": "2022-11-16T07:30:44.307375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We've now got what we need to implement our neural network.\n",
    "\n",
    "First, we'll need to create coefficients for each of our layers. Our first set of coefficients will take our `n_coeff` inputs, and create `n_hidden` outputs. We can choose whatever `n_hidden` we like -- a higher number gives our network more flexibility, but makes it slower and harder to train. So we need a matrix of size `n_coeff` by `n_hidden`. We'll divide these coefficients by `n_hidden` so that when we sum them up in the next layer we'll end up with similar magnitude numbers to what we started with.\n",
    "\n",
    "Then our second layer will need to take the `n_hidden` inputs and create a single output, so that means we need a `n_hidden` by `1` matrix there. The second layer will also need a constant term added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c32783c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:44.761500Z",
     "iopub.status.busy": "2022-11-16T07:30:44.761066Z",
     "iopub.status.idle": "2022-11-16T07:30:44.768884Z",
     "shell.execute_reply": "2022-11-16T07:30:44.768207Z"
    },
    "papermill": {
     "duration": 0.169194,
     "end_time": "2022-11-16T07:30:44.770664",
     "exception": false,
     "start_time": "2022-11-16T07:30:44.601470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1722,  0.2324, -0.3575, -0.0010, -0.1833, -0.2411,  0.0489,  0.0866, -0.0534,  0.3132, -0.1487, -0.2551,  0.3328,  0.1292,\n",
       "          0.2361, -0.2622,  0.4051, -0.2674, -0.2312,  0.1147],\n",
       "        [ 0.4072,  0.2834,  0.0835, -0.0504,  0.4354, -0.3408, -0.4552,  0.1447, -0.4648, -0.3039, -0.1297, -0.0850,  0.4682,  0.3973,\n",
       "         -0.4849,  0.2098, -0.3018,  0.4185,  0.1089,  0.0791],\n",
       "        [-0.1708, -0.1882,  0.4861, -0.2534, -0.2502, -0.0770,  0.3336, -0.4975, -0.2561,  0.0892, -0.4670,  0.3725, -0.1095,  0.3443,\n",
       "         -0.3448,  0.1112, -0.2866,  0.0245, -0.1640, -0.0845],\n",
       "        [-0.1318,  0.3686,  0.3743,  0.4772, -0.0329, -0.3076,  0.1449,  0.3728,  0.1066, -0.1043, -0.4297, -0.0069, -0.2685,  0.2132,\n",
       "         -0.0946, -0.4802,  0.1940,  0.0919,  0.2913, -0.2694],\n",
       "        [ 0.4454, -0.2993,  0.1581,  0.3215, -0.1481,  0.2920,  0.0677,  0.2740,  0.2386, -0.2730, -0.3255, -0.3695,  0.1019, -0.2950,\n",
       "         -0.3885, -0.3118, -0.1861,  0.3498, -0.4068, -0.3355],\n",
       "        [-0.4195,  0.4183,  0.0745, -0.2618,  0.1313,  0.1043, -0.1724,  0.2857,  0.1229, -0.1264, -0.3666, -0.1924,  0.2897, -0.3271,\n",
       "          0.0228,  0.1612, -0.1394,  0.4221, -0.0308, -0.2891],\n",
       "        [-0.3974,  0.0643,  0.0065,  0.2851,  0.0101,  0.2865, -0.2499, -0.3194, -0.0428,  0.2932, -0.1902, -0.4145, -0.1962, -0.1351,\n",
       "         -0.1406, -0.0908, -0.3329,  0.0873, -0.2703,  0.1628],\n",
       "        [-0.2271,  0.0397, -0.1825,  0.0371,  0.3826, -0.3378, -0.1353, -0.1325, -0.0484,  0.4183, -0.3299,  0.4589,  0.4941,  0.0707,\n",
       "          0.4651,  0.3530,  0.0762,  0.1317,  0.1661,  0.0818],\n",
       "        [-0.4650, -0.3994, -0.3703, -0.0912, -0.2068,  0.2324, -0.4656, -0.4877,  0.3365, -0.3951,  0.2695,  0.4371, -0.0985, -0.2637,\n",
       "         -0.0712, -0.4714,  0.3475, -0.2116, -0.0679, -0.2907],\n",
       "        [-0.2086,  0.4594, -0.1492, -0.3911,  0.3088, -0.0719, -0.4050,  0.3429,  0.1524,  0.0166, -0.4796,  0.2852,  0.0615,  0.0503,\n",
       "         -0.2562,  0.0253, -0.3938,  0.3821,  0.4183,  0.2715],\n",
       "        [-0.2130, -0.4010, -0.2978,  0.4096, -0.0851, -0.4942,  0.3208, -0.4139, -0.4086,  0.2151, -0.4306, -0.4858,  0.0428, -0.0674,\n",
       "         -0.1172,  0.2743, -0.4395, -0.2553,  0.2083,  0.3248],\n",
       "        [-0.4198, -0.3337, -0.4108,  0.1121,  0.3272, -0.3012,  0.4801,  0.0653,  0.3900,  0.0846, -0.1057, -0.3032, -0.4705, -0.1387,\n",
       "          0.1520,  0.0367,  0.3844,  0.0475, -0.1029, -0.3455]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.rand(n_coeff, 20)-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c93b48d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:45.091289Z",
     "iopub.status.busy": "2022-11-16T07:30:45.091053Z",
     "iopub.status.idle": "2022-11-16T07:30:45.095594Z",
     "shell.execute_reply": "2022-11-16T07:30:45.094923Z"
    },
    "papermill": {
     "duration": 0.16482,
     "end_time": "2022-11-16T07:30:45.097174",
     "exception": false,
     "start_time": "2022-11-16T07:30:44.932354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):\n",
    "    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden\n",
    "    layer2 = torch.rand(n_hidden, 1)-0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f760f14",
   "metadata": {
    "papermill": {
     "duration": 0.149315,
     "end_time": "2022-11-16T07:30:45.395672",
     "exception": false,
     "start_time": "2022-11-16T07:30:45.246357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we have our coefficients, we can create our neural net. The key steps are the two matrix products, `indeps@l1` and `res@l2` (where `res` is the output of the first layer). The first layer output is passed to `F.relu` (that's our non-linearity), and the second is passed to `torch.sigmoid` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a661aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:45.695146Z",
     "iopub.status.busy": "2022-11-16T07:30:45.693952Z",
     "iopub.status.idle": "2022-11-16T07:30:45.699921Z",
     "shell.execute_reply": "2022-11-16T07:30:45.699384Z"
    },
    "papermill": {
     "duration": 0.156573,
     "end_time": "2022-11-16T07:30:45.701698",
     "exception": false,
     "start_time": "2022-11-16T07:30:45.545125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    l1,l2,const = coeffs # layer1, layer2 and const brought in\n",
    "    res = F.relu(indeps@l1) #multiplied to each of 20 sets of coeffs, relued all\n",
    "    res = res@l2 + const #multiplied to last layer without making this relu and adding to coeff\n",
    "    return torch.sigmoid(res) #torch.sigmoid the final preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c91d2",
   "metadata": {
    "papermill": {
     "duration": 0.147554,
     "end_time": "2022-11-16T07:30:45.996455",
     "exception": false,
     "start_time": "2022-11-16T07:30:45.848901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, now that we have more than one set of coefficients, we need to add a loop to update each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c55d047a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:46.292894Z",
     "iopub.status.busy": "2022-11-16T07:30:46.292502Z",
     "iopub.status.idle": "2022-11-16T07:30:46.295968Z",
     "shell.execute_reply": "2022-11-16T07:30:46.295538Z"
    },
    "papermill": {
     "duration": 0.153665,
     "end_time": "2022-11-16T07:30:46.298018",
     "exception": false,
     "start_time": "2022-11-16T07:30:46.144353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr): #this will update each of the set of coeffs, and even the final const layer\n",
    "    for layer in coeffs: #all three l1,l2,const under purview\n",
    "        layer.sub_(layer.grad * lr) #for each of them grads are taken and subtracted\n",
    "        layer.grad.zero_() #everytime grads are made 0 cuz loss.backward again adds grad values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "337af79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:46.595697Z",
     "iopub.status.busy": "2022-11-16T07:30:46.595343Z",
     "iopub.status.idle": "2022-11-16T07:30:46.600296Z",
     "shell.execute_reply": "2022-11-16T07:30:46.599496Z"
    },
    "papermill": {
     "duration": 0.156541,
     "end_time": "2022-11-16T07:30:46.602496",
     "exception": false,
     "start_time": "2022-11-16T07:30:46.445955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_epoch(coeffs,lr): #this means one iteration thru the neural net\n",
    "    loss = calc_loss(coeffs,trn_indep,trn_dep) #this just uses the calc_preds\n",
    "    loss.backward() #activates the grads of the coeffs\n",
    "    with torch.no_grad(): update_coeffs(coeffs,lr) #this is fine\n",
    "    print(f\"Loss {loss:.3f}\", end=\"; \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "65318b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:46.899990Z",
     "iopub.status.busy": "2022-11-16T07:30:46.899598Z",
     "iopub.status.idle": "2022-11-16T07:30:46.902947Z",
     "shell.execute_reply": "2022-11-16T07:30:46.902488Z"
    },
    "papermill": {
     "duration": 0.155214,
     "end_time": "2022-11-16T07:30:46.905137",
     "exception": false,
     "start_time": "2022-11-16T07:30:46.749923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean() #this is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9621fe8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:47.205820Z",
     "iopub.status.busy": "2022-11-16T07:30:47.205459Z",
     "iopub.status.idle": "2022-11-16T07:30:47.209967Z",
     "shell.execute_reply": "2022-11-16T07:30:47.209182Z"
    },
    "papermill": {
     "duration": 0.156845,
     "end_time": "2022-11-16T07:30:47.212158",
     "exception": false,
     "start_time": "2022-11-16T07:30:47.055313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(epochs=30,lr=0.01):\n",
    "    torch.manual_seed(442)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55344e72",
   "metadata": {
    "papermill": {
     "duration": 0.149421,
     "end_time": "2022-11-16T07:30:47.509010",
     "exception": false,
     "start_time": "2022-11-16T07:30:47.359589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That's it -- we're now ready to train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1d94bc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:47.807342Z",
     "iopub.status.busy": "2022-11-16T07:30:47.806972Z",
     "iopub.status.idle": "2022-11-16T07:30:47.836368Z",
     "shell.execute_reply": "2022-11-16T07:30:47.835694Z"
    },
    "papermill": {
     "duration": 0.180051,
     "end_time": "2022-11-16T07:30:47.838160",
     "exception": false,
     "start_time": "2022-11-16T07:30:47.658109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.543; Loss 0.532; Loss 0.520; Loss 0.505; Loss 0.487; Loss 0.466; Loss 0.439; Loss 0.407; Loss 0.373; Loss 0.343; Loss 0.319; Loss 0.301; Loss 0.286; Loss 0.274; Loss 0.264; Loss 0.256; Loss 0.250; Loss 0.245; Loss 0.240; Loss 0.237; Loss 0.234; Loss 0.231; Loss 0.229; Loss 0.227; Loss 0.226; Loss 0.224; Loss 0.223; Loss 0.222; Loss 0.221; Loss 0.220; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6109758d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:48.134343Z",
     "iopub.status.busy": "2022-11-16T07:30:48.134096Z",
     "iopub.status.idle": "2022-11-16T07:30:48.156047Z",
     "shell.execute_reply": "2022-11-16T07:30:48.155499Z"
    },
    "papermill": {
     "duration": 0.173719,
     "end_time": "2022-11-16T07:30:48.157560",
     "exception": false,
     "start_time": "2022-11-16T07:30:47.983841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.543; Loss 0.400; Loss 0.260; Loss 0.390; Loss 0.221; Loss 0.211; Loss 0.197; Loss 0.195; Loss 0.193; Loss 0.193; Loss 0.193; Loss 0.193; Loss 0.193; Loss 0.193; Loss 0.193; Loss 0.193; Loss 0.193; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; Loss 0.192; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e0c14",
   "metadata": {
    "papermill": {
     "duration": 0.148315,
     "end_time": "2022-11-16T07:30:48.452868",
     "exception": false,
     "start_time": "2022-11-16T07:30:48.304553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's looking good -- our loss is lower than before. Let's see if that translates to a better result on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "164cf85a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:48.749349Z",
     "iopub.status.busy": "2022-11-16T07:30:48.748448Z",
     "iopub.status.idle": "2022-11-16T07:30:48.755381Z",
     "shell.execute_reply": "2022-11-16T07:30:48.754623Z"
    },
    "papermill": {
     "duration": 0.156922,
     "end_time": "2022-11-16T07:30:48.757229",
     "exception": false,
     "start_time": "2022-11-16T07:30:48.600307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5cc8c",
   "metadata": {
    "papermill": {
     "duration": 0.148115,
     "end_time": "2022-11-16T07:30:49.053490",
     "exception": false,
     "start_time": "2022-11-16T07:30:48.905375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this case our neural net isn't showing better results than the linear model. That's not surprising; this dataset is very small and very simple, and isn't the kind of thing we'd expect to see neural networks excel at. Furthermore, our validation set is too small to reliably see much accuracy difference. But the key thing is that we now know exactly what a real neural net looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85563862",
   "metadata": {
    "papermill": {
     "duration": 0.147362,
     "end_time": "2022-11-16T07:30:49.346852",
     "exception": false,
     "start_time": "2022-11-16T07:30:49.199490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fab439",
   "metadata": {
    "papermill": {
     "duration": 0.145079,
     "end_time": "2022-11-16T07:30:49.638869",
     "exception": false,
     "start_time": "2022-11-16T07:30:49.493790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The neural net in the previous section only uses one hidden layer, so it doesn't count as \"deep\" learning. But we can use the exact same technique to make our neural net deep, by adding more matrix multiplications.\n",
    "\n",
    "First, we'll need to create additional coefficients for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "04b548fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:49.940836Z",
     "iopub.status.busy": "2022-11-16T07:30:49.939772Z",
     "iopub.status.idle": "2022-11-16T07:30:49.945780Z",
     "shell.execute_reply": "2022-11-16T07:30:49.944806Z"
    },
    "papermill": {
     "duration": 0.159351,
     "end_time": "2022-11-16T07:30:49.947619",
     "exception": false,
     "start_time": "2022-11-16T07:30:49.788268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 10, 10, 1]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens = [10,10]\n",
    "hiddens\n",
    "[n_coeff] + hiddens + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "865a637e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:50.251728Z",
     "iopub.status.busy": "2022-11-16T07:30:50.251472Z",
     "iopub.status.idle": "2022-11-16T07:30:50.257948Z",
     "shell.execute_reply": "2022-11-16T07:30:50.256442Z"
    },
    "papermill": {
     "duration": 0.161447,
     "end_time": "2022-11-16T07:30:50.260662",
     "exception": false,
     "start_time": "2022-11-16T07:30:50.099215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    hiddens = [10, 10]  # <-- set this to the size of each hidden layer you want\n",
    "    sizes = [n_coeff] + hiddens + [1]\n",
    "    n = len(sizes)\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    return layers,consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "667e5c73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:50.579487Z",
     "iopub.status.busy": "2022-11-16T07:30:50.579021Z",
     "iopub.status.idle": "2022-11-16T07:30:50.584188Z",
     "shell.execute_reply": "2022-11-16T07:30:50.583564Z"
    },
    "papermill": {
     "duration": 0.158987,
     "end_time": "2022-11-16T07:30:50.586143",
     "exception": false,
     "start_time": "2022-11-16T07:30:50.427156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhiddens = [10, 10]  # <-- set this to the size of each hidden layer you want\\nsizes = [n_coeff] + hiddens + [1]\\nn = len(sizes)\\nlayers = torch((torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1))\\nlayers\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "hiddens = [10, 10]  # <-- set this to the size of each hidden layer you want\n",
    "sizes = [n_coeff] + hiddens + [1]\n",
    "n = len(sizes)\n",
    "layers = torch((torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1))\n",
    "layers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524699d",
   "metadata": {
    "papermill": {
     "duration": 0.149064,
     "end_time": "2022-11-16T07:30:50.883829",
     "exception": false,
     "start_time": "2022-11-16T07:30:50.734765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You'll notice here that there's a lot of messy constants to get the random numbers in just the right ranges. When you train the model in a moment, you'll see that the tiniest changes to these initialisations can cause our model to fail to train at all! This is a key reason that deep learning failed to make much progress in the early days -- it's very finicky to get a good starting point for our coefficients. Nowadays, we have ways to deal with that, which we'll learn about in other notebooks.\n",
    "\n",
    "Our deep learning `calc_preds` looks much the same as before, but now we loop through each layer, instead of listing them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5480c085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:51.186223Z",
     "iopub.status.busy": "2022-11-16T07:30:51.185946Z",
     "iopub.status.idle": "2022-11-16T07:30:51.190961Z",
     "shell.execute_reply": "2022-11-16T07:30:51.190265Z"
    },
    "papermill": {
     "duration": 0.15907,
     "end_time": "2022-11-16T07:30:51.193304",
     "exception": false,
     "start_time": "2022-11-16T07:30:51.034234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    layers,consts = coeffs\n",
    "    n = len(layers)\n",
    "    res = indeps\n",
    "    for i,l in enumerate(layers):\n",
    "        res = res@l + consts[i]\n",
    "        if i!=n-1: res = F.relu(res) #why not on n-1 also? I guess its like layer's constant term, think abt it, without no -ve value will come.\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186ab47",
   "metadata": {
    "papermill": {
     "duration": 0.152815,
     "end_time": "2022-11-16T07:30:51.496793",
     "exception": false,
     "start_time": "2022-11-16T07:30:51.343978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also need a minor update to `update_coeffs` since we've got `layers` and `consts` separated now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17c6ff71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:51.798369Z",
     "iopub.status.busy": "2022-11-16T07:30:51.797954Z",
     "iopub.status.idle": "2022-11-16T07:30:51.801364Z",
     "shell.execute_reply": "2022-11-16T07:30:51.800908Z"
    },
    "papermill": {
     "duration": 0.155241,
     "end_time": "2022-11-16T07:30:51.802858",
     "exception": false,
     "start_time": "2022-11-16T07:30:51.647617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    layers,consts = coeffs\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f934069",
   "metadata": {
    "papermill": {
     "duration": 0.151006,
     "end_time": "2022-11-16T07:30:52.104117",
     "exception": false,
     "start_time": "2022-11-16T07:30:51.953111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's train our model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "261bd2ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:52.405879Z",
     "iopub.status.busy": "2022-11-16T07:30:52.405599Z",
     "iopub.status.idle": "2022-11-16T07:30:52.432787Z",
     "shell.execute_reply": "2022-11-16T07:30:52.432177Z"
    },
    "papermill": {
     "duration": 0.179297,
     "end_time": "2022-11-16T07:30:52.434452",
     "exception": false,
     "start_time": "2022-11-16T07:30:52.255155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.521; Loss 0.483; Loss 0.427; Loss 0.379; Loss 0.379; Loss 0.379; Loss 0.379; Loss 0.378; Loss 0.378; Loss 0.378; Loss 0.378; Loss 0.378; Loss 0.378; Loss 0.378; Loss 0.378; Loss 0.378; Loss 0.377; Loss 0.376; Loss 0.371; Loss 0.333; Loss 0.239; Loss 0.224; Loss 0.208; Loss 0.204; Loss 0.203; Loss 0.203; Loss 0.207; Loss 0.197; Loss 0.196; Loss 0.195; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861f4cd",
   "metadata": {
    "papermill": {
     "duration": 0.147991,
     "end_time": "2022-11-16T07:30:52.735406",
     "exception": false,
     "start_time": "2022-11-16T07:30:52.587415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "...and check its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "183d5080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T07:30:53.038836Z",
     "iopub.status.busy": "2022-11-16T07:30:53.037634Z",
     "iopub.status.idle": "2022-11-16T07:30:53.044673Z",
     "shell.execute_reply": "2022-11-16T07:30:53.043965Z"
    },
    "papermill": {
     "duration": 0.15943,
     "end_time": "2022-11-16T07:30:53.046931",
     "exception": false,
     "start_time": "2022-11-16T07:30:52.887501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4b9ea",
   "metadata": {
    "papermill": {
     "duration": 0.153178,
     "end_time": "2022-11-16T07:30:53.351397",
     "exception": false,
     "start_time": "2022-11-16T07:30:53.198219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496951b3",
   "metadata": {
    "papermill": {
     "duration": 0.199947,
     "end_time": "2022-11-16T07:30:53.703266",
     "exception": false,
     "start_time": "2022-11-16T07:30:53.503319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's actually pretty cool that we've managed to create a real deep learning model from scratch and trained it to get over 80% accuracy on this task, all in the course of a single notebook!\n",
    "\n",
    "The \"real\" deep learning models that are used in research and industry look very similar to this, and in fact if you look inside the source code of any deep learning model you'll recognise the basic steps are the same.\n",
    "\n",
    "The biggest differences in practical models to what we have above are:\n",
    "\n",
    "- How initialisation and normalisation is done to ensure the model trains correctly every time\n",
    "- Regularization (to avoid over-fitting)\n",
    "- Modifying the neural net itself to take advantage of knowledge of the problem domain\n",
    "- Doing gradient descent steps on smaller batches, rather than the whole dataset.\n",
    "\n",
    "I'll be adding notebooks about all these later, and will add links here once they're ready.\n",
    "\n",
    "If you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. (BTW, be sure you're looking at my [original notebook here](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch) when you do that, and are not on your own copy of it, otherwise your upvote won't get counted!) And if you have any questions or comments, please pop them below -- I read every comment I receive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f33403",
   "metadata": {
    "papermill": {
     "duration": 0.149502,
     "end_time": "2022-11-16T07:30:54.002926",
     "exception": false,
     "start_time": "2022-11-16T07:30:53.853424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.004866,
   "end_time": "2022-11-16T07:30:55.075337",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-16T07:29:46.070471",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
